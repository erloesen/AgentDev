{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "668d7cfd-3bc5-4ccd-8a3b-abf7d0a4141e",
   "metadata": {},
   "source": [
    "## <center> 《2025大模型Agent智能体开发实战》体验课\n",
    "## <center> Ch 1.DeepSeek v3 API接入指南"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc8c6167-92bf-4a5b-8b8e-e962efef7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Code, Markdown\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd00aa-54e8-4b03-b209-0b454b9587af",
   "metadata": {},
   "source": [
    "- DeepSeek v3账号注册与API获取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e067d-e138-4061-aa11-df8ace914142",
   "metadata": {},
   "source": [
    "DeepSeek官网：https://www.deepseek.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c53661-a607-4f8e-abcd-52ec2eb4e0e3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107155848673.png\" alt=\"image-20250107155848673\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90415dc9-6e5f-4227-8b61-d33cc6f7948f",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107155925049.png\" alt=\"image-20250107155925049\" style=\"zoom:25%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9c050-d0cf-4f50-b220-e6b39607a48c",
   "metadata": {},
   "source": [
    "新用户注册即赠送10元额度，约500万token额度："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e17b9-f1dd-4129-812f-c0303f98ad9e",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107160101536.png\" alt=\"image-20250107160101536\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945b7cb-e708-4c20-ba23-f70388044b57",
   "metadata": {},
   "source": [
    "对比GPT4o价格，约降低90%以上：输入价格为GPT4o的6%，输出价格围殴GPT4o的3%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d704a-1a75-46eb-9cd5-ea0fb42fa1ea",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107160418665.png\" alt=\"image-20250107160418665\" style=\"zoom: 50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a9644-b8ba-442b-a3b8-8cca6939a01d",
   "metadata": {},
   "source": [
    "且API调用不限速："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed8749-1528-46a8-a18d-ca9a08d1cad3",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107160659366.png\" alt=\"image-20250107160659366\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40392df9-2cec-4ac3-b3e7-8da2c29bd7f2",
   "metadata": {},
   "source": [
    "最关键的是，调用风格和OpenAI完全一致：Function calling、提示词缓存、Json Output等功能完全相同："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74d277-4a00-4994-98e3-281f10aa2ce5",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107161014344.png\" alt=\"image-20250107161014344\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d05c729-51c6-4678-ae0a-1cb926697e1c",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107161058708.png\" alt=\"image-20250107161058708\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d5ece-eb1e-4ba6-8194-9829b480298a",
   "metadata": {},
   "source": [
    "- DeepSeek v3调用流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975e4f9-c4a4-48e8-bd84-b1391d7d03ee",
   "metadata": {},
   "source": [
    "对比OpenAI GPT4o调用流程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d315fff-4669-4cff-8aaa-7f4c236e8b4a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /root/anaconda3/lib/python3.12/site-packages (1.57.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /root/anaconda3/lib/python3.12/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /root/anaconda3/lib/python3.12/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /root/anaconda3/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /root/anaconda3/lib/python3.12/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /root/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /root/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /root/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /root/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /root/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6820887-b857-49b4-82bd-a1310c3932d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79027151-e815-48a0-8221-dc5e7f330f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.57.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb547f9-d977-4720-b681-d3b3a6e4b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ef31212-e4be-4c14-8ae5-39a18b98b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b374eb0-a2c6-44cc-ac4f-67b1591ffb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化客户端\n",
    "client = OpenAI(api_key=api_key, \n",
    "                base_url=\"https://ai.devtool.tech/proxy/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79900538-4866-4808-a8f5-3ad701aadd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 GPT-4o-mini 模型\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好，好久不见!\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296eaef-e6b1-4b08-afc6-5493e11ba735",
   "metadata": {},
   "source": [
    "上述代码中 model 参数指定了使用的模型（gpt-4o-mini），messages 列表定义了对话内容，其中 role 为 user 表示用户的输入内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ba9ab34-6d99-409f-9cfb-c73eb8f4d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！很高兴再次见到你！你最近怎么样？\n"
     ]
    }
   ],
   "source": [
    "# 输出生成的响应内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e8546c-8f24-400f-85bc-d965ed153af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AmyljFoOE3EPBcKgrc2MxlUTs4Nfe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='你好！很高兴再次见到你！你最近怎么样？', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736236703, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_d02d531b47', usage=CompletionUsage(completion_tokens=15, prompt_tokens=13, total_tokens=28, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5688400-84c7-489a-ad27-a6b50ce5598f",
   "metadata": {},
   "source": [
    "DeepSeekv3调用流程:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7becbca-f7e7-4d4b-bdcf-71a36715ac4d",
   "metadata": {},
   "source": [
    "首先在官网申请API-KEY：https://platform.deepseek.com/api_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd575c0f-cd7b-4520-925f-7347a04a5fd0",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107162553252.png\" alt=\"image-20250107162553252\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52283a-e45f-4222-a963-2a57381461e2",
   "metadata": {},
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250107162642821.png\" alt=\"image-20250107162642821\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "239f436e-6480-451c-8dcc-de068064b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_api_key = 'YOUR_DS_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9317da14-7b61-4819-b979-00691d04b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化客户端\n",
    "client = OpenAI(api_key=ds_api_key, \n",
    "                base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fbb4ca-3901-4458-975b-f142547380ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 deepseekv3 模型\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"你好，好久不见!\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86fca2e7-aecb-400f-8669-347011679baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！好久不见！最近过得怎么样？有什么想聊的吗？\n"
     ]
    }
   ],
   "source": [
    "# 输出生成的响应内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69403a69-6962-4c6e-a328-6e24bd1ecda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='1fdbc70b-acbf-4c9a-a895-d26bd69ad531', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='你好！好久不见！最近过得怎么样？有什么想聊的吗？', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736238514, model='deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='fp_3a5770e1b4', usage=CompletionUsage(completion_tokens=14, prompt_tokens=8, total_tokens=22, completion_tokens_details=None, prompt_tokens_details=None, prompt_cache_hit_tokens=0, prompt_cache_miss_tokens=8))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0184c-5632-49c2-b210-3cadb63b5bf8",
   "metadata": {},
   "source": [
    "一样的SDK，代表DeepSeek模型采用和GPT模型完全的参数体系："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd56ab0-247c-407e-b0b9-ab35eb2e6795",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[ChatCompletionMessageParam]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[str, ChatModel]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maudio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[ChatCompletionAudioParam] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfrequency_penalty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[float] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfunction_call\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'completion_create_params.FunctionCall | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfunctions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[completion_create_params.Function] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogit_bias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Dict[str, int]] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogprobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[bool] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_completion_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Dict[str, str]] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodalities\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[List[ChatCompletionModality]] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparallel_tool_calls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[ChatCompletionPredictionContentParam] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpresence_penalty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[float] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mresponse_format\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'completion_create_params.ResponseFormat | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mservice_tier\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Optional[Literal['auto', 'default']] | NotGiven\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[Optional[str], List[str]] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[bool] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Literal[False]] | Literal[True] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstream_options\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[ChatCompletionStreamOptionsParam] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[float] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtool_choice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ChatCompletionToolChoiceOptionParam | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtools\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Iterable[ChatCompletionToolParam] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtop_logprobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtop_p\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[float] | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muser\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextra_headers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Headers | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextra_query\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Query | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextra_body\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Body | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float | httpx.Timeout | None | NotGiven'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'ChatCompletion | Stream[ChatCompletionChunk]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.12/site-packages/openai/resources/chat/completions.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.chat.completions.create?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c80c0-24f3-40db-a442-d623d38f191c",
   "metadata": {},
   "source": [
    "DeepSeek目前支持的模型范围："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f0d603a-f3a3-48d0-95e8-e26dea8e6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409cb1a7-af02-4152-8123-569660b65914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='deepseek-chat', created=None, object='model', owned_by='deepseek'),\n",
       " Model(id='deepseek-coder', created=None, object='model', owned_by='deepseek')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_list.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce289098-87ca-4256-9843-6a83e1f262bc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;DeepSeek v3 模型属于聊天补全（chat completion）模型，模型提供了多种参数，帮助开发者定制化模型的生成行为。以下是对主要参数的详细解释，以及如何在 Python 中使用这些参数进行请求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec77815-a7ae-4e07-911b-a927f8e0b069",
   "metadata": {},
   "source": [
    "#### 4.1 `messages` (必填)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781792d0-e72f-46e9-a977-f75a2c722c15",
   "metadata": {},
   "source": [
    "&emsp;&emsp;`messages` 参数是 DeepSeek v3  模型 API 中必填的参数之一，用于定义聊天上下文，包括用户的输入、系统的指令、助手的回复等。通过 `messages` 数组，模型可以理解当前对话的背景，从而生成更加连贯的响应。根据不同的使用场景，`messages` 包含多种类型的消息，例如 `system message`、`user message` 和 `assistant message`。下面是对 `messages` 参数及其各个子类型的详细解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f41939-65d6-4e43-833e-92da03fb2521",
   "metadata": {},
   "source": [
    "##### 4.1.1 `System message`\n",
    "&emsp;&emsp;`system message` 用于设置系统消息，通常由开发者设定，以指导模型如何进行对话。这类消息可以定义规则或约束，并提供有关对话的背景信息。\n",
    "\n",
    "- **`content`** (必填)：系统消息的内容，可以是字符串或数组。如果是数组，可能包含多个类型的内容（如文本、图像）。\n",
    "- **`role`** (必填)：此处角色为 `system`，表明这是系统发出的消息。\n",
    "- **`name`** (可选)：提供系统消息发送者的名称，尤其适用于区分多个具有相同角色的参与者。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"你是一位助人为乐的助手。\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc4ccecb-d361-4c36-8542-8c760ba18496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下代码的注释由MateGen生成:\n",
    "# 定义一个字典，键为'system_message'，用于存储系统消息\n",
    "system_message = {\n",
    "    # 'role'键对应的值是一个字符串\"system\"，表示消息的发送者是系统\n",
    "    \"role\": \"system\",\n",
    "    # 'content'键对应的值是一个字符串，表示系统消息的内容\n",
    "    \"content\": \"你是一位大学教授。\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc9b146-4213-4eca-8d15-8926c2304755",
   "metadata": {},
   "source": [
    "##### 4.1.2 `User message`\n",
    "`user message` 表示用户发给模型的消息，是对话的核心部分之一。它定义了用户的输入内容，模型根据这些内容生成响应。\n",
    "\n",
    "- **`content`** (必填)：用户消息的内容，通常为文本或图像链接的数组。对于支持图像输入的模型，如 DeepSeek v2.5 ，还可以传递图像。\n",
    "  - **文本内容**：单纯的字符串形式，用户输入的文本。\n",
    "  - **数组形式的内容**：由文本或图像链接组成的数组，可以同时传递多张图像或多段文本内容。\n",
    "- **`role`** (必填)：角色为 `user`，表示该消息来自用户。\n",
    "- **`name`** (可选)：可以为用户指定一个名称，用于区分多个具有相同角色的用户。\n",
    "\n",
    "**示例**：\n",
    "```python\n",
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"你好，请介绍下你自己。\"\n",
    "}\n",
    "```\n",
    "\n",
    "如果传递多个内容（如图像和文本）：\n",
    "```python\n",
    "user_message_with_image = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"你能帮我介绍下这张图片里面的内容么？\"},\n",
    "        {\"type\": \"image_url\", \n",
    "         \"image_url\": {\n",
    "                        \"url\": \"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20241009205714055.png\",\n",
    "                    }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16395dc5-ec83-4efd-b272-c6c23b3f22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建用户消息\n",
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"你好，请介绍下你自己。\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab616bd0-578b-4d7c-994a-19d88aba8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 GPT-4o-mini 模型\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        system_message,\n",
    "        user_message\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3255209d-ab1e-4c2b-b46f-b51ff762dc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一位大学教授，专注于多个学科领域的研究与教学。我的工作主要包括教授本科生和研究生课程，指导学生的研究项目，以及进行学术研究。我致力于通过教育和研究推动知识的边界，并帮助学生发展他们的批判性思维和创新能力。此外，我也参与学术会议和研讨会，与同行交流最新的研究成果和教学方法。如果你有任何学术上的问题或需要指导，我很乐意提供帮助。\n"
     ]
    }
   ],
   "source": [
    "# 输出生成的响应内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd225425-885f-4a83-95de-9604a32ca26b",
   "metadata": {},
   "source": [
    "- 构建多轮对话机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b165a1c4-6316-47d8-8c0a-58b4ae83e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import display, Code, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe250202-e25b-4046-a733-1042ae208c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url_and_text(input_text):\n",
    "    \"\"\"\n",
    "    提取用户输入中的 URL 和描述文本。\n",
    "    \n",
    "    参数:\n",
    "    input_text (str): 用户的输入文本，可能包含 URL 和描述性文本。\n",
    "\n",
    "    返回:\n",
    "    tuple: 包含描述性文本和提取到的 URL，如果没有 URL，则返回 (input_text, None)。\n",
    "    \"\"\"\n",
    "    # 使用正则表达式检测 URL\n",
    "    url_pattern = re.compile(r'(https?://[^\\s]+)')\n",
    "    url_match = url_pattern.search(input_text)\n",
    "    \n",
    "    if url_match:\n",
    "        # 提取 URL 并将其从原文本中移除\n",
    "        url = url_match.group(0)\n",
    "        description = input_text.replace(url, '').strip()  # 去掉 URL 后剩下的文本\n",
    "        return description, url\n",
    "    else:\n",
    "        return input_text, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67e4e1ef-eaef-4cc3-b49a-a59d26c5aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message(role, content):\n",
    "    \"\"\"\n",
    "    创建标准的消息格式，包括用户、助手或系统消息。\n",
    "\n",
    "    参数:\n",
    "    role (str): 消息的角色，值为 \"user\"、\"assistant\" 或 \"system\"。\n",
    "    content (str or list): 消息的内容，可以是字符串（文本）或包含文本和图像的数组。\n",
    "\n",
    "    返回:\n",
    "    dict: 符合 GPT-4o API 要求的消息格式。\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"role\": role,\n",
    "        \"content\": content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7a2ba6f-cca6-4e7f-a747-6115026ce857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_input(input_text):\n",
    "    \"\"\"\n",
    "    根据用户输入的内容，灵活判断是否包含 URL，并生成对应的消息格式。\n",
    "\n",
    "    参数:\n",
    "    input_text (str): 用户的输入文本。\n",
    "\n",
    "    返回:\n",
    "    dict: 生成的用户消息，包含文本或图片 URL。\n",
    "    \"\"\"\n",
    "    description, url = extract_url_and_text(input_text)\n",
    "    \n",
    "    if url:\n",
    "        # 如果检测到 URL，生成带图像链接的消息\n",
    "        if not description:\n",
    "            description = \"请帮我分析这张图片的内容。\"  # 如果没有描述，提供默认描述\n",
    "        return create_user_message_with_image(description, url)\n",
    "    else:\n",
    "        # 否则生成普通的文本消息\n",
    "        return create_message(\"user\", description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7096dd6-6bcb-4ec6-8baf-d12ed6095a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_message_with_image(text, image_url):\n",
    "    \"\"\"\n",
    "    创建包含文本和图像链接的用户消息。\n",
    "\n",
    "    参数:\n",
    "    text (str): 用户输入的文本内容。\n",
    "    image_url (str): 图像的 URL 地址。\n",
    "\n",
    "    返回:\n",
    "    dict: 包含文本和图像的用户消息。\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": text},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "132e86ce-c65a-44af-9918-b4d96e7b23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_DeepSeek(client, messages):\n",
    "    \"\"\"\n",
    "    使用 DeepSeek 模型进行多轮对话的核心函数。\n",
    "\n",
    "    参数:\n",
    "    client (OpenAI): 实例化的 OpenAI 客户端。\n",
    "    messages (list): 包含对话上下文的消息列表，包括用户、助手和系统消息。\n",
    "\n",
    "    返回:\n",
    "    str: GPT-4o 模型生成的回复内容。\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # 使用 deepseek-chat 模型\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # 提取并返回助手生成的回复内容\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "654f657c-8875-42ce-b3c0-ef039f7ad54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_round_chat():\n",
    "    \"\"\"\n",
    "    多轮对话机器人示例函数，演示如何通过捕获用户输入，并根据是否包含 URL 做出响应。\n",
    "\n",
    "    \"\"\"\n",
    "    # 初始化消息列表，包含系统消息\n",
    "    messages = []\n",
    "    \n",
    "    # 创建系统消息，设置对话的上下文\n",
    "    system_message = create_message(\"system\", \"You are a helpful assistant.\")\n",
    "    messages.append(system_message)\n",
    "    \n",
    "    while True:\n",
    "        # 捕获用户输入\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # 处理用户输入并生成相应的消息\n",
    "        user_message = process_user_input(user_input)\n",
    "        messages.append(user_message)\n",
    "        \n",
    "        # 调用 GPT-4o 模型进行回复\n",
    "        assistant_reply = chat_with_DeepSeek(client, messages)\n",
    "        display(Markdown(f\"Assistant: {assistant_reply}\"))\n",
    "        \n",
    "        # 将助手回复添加到消息列表\n",
    "        messages.append(create_message(\"assistant\", assistant_reply))\n",
    "        \n",
    "        # 提供退出机制，用户可以输入 'exit' 退出对话\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"对话结束。\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "647ea680-f702-4a67-a01f-5fc117b94e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  你好，好久不见！\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: 你好！好久不见，很高兴再次见到你！最近过得怎么样？有什么新鲜事想分享吗？"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  我叫陈明，请介绍下你自己\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: 陈明，你好！我是一个人工智能助手，专门设计来提供信息、解答疑问和协助解决问题。我没有实体形态，但我的“大脑”里装满了各种知识，从科学、历史到文化、技术等。我可以帮助你查找资料、学习新知识、解决数学问题，或者仅仅是聊聊天。我的目标是让你的生活更加便捷和有趣。有什么我可以帮你的吗？"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  请问我叫什么名字？\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: 你刚才告诉我，你的名字是陈明。如果有什么需要帮助的，尽管告诉我，陈明！"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: 好的，陈明！如果你有任何其他问题或需要帮助，随时欢迎回来。祝你有个美好的一天！再见！"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对话结束。\n"
     ]
    }
   ],
   "source": [
    "# 调用多轮对话机器人函数\n",
    "multi_round_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f2363-36a2-4226-9aec-a187a268fac8",
   "metadata": {},
   "source": [
    "### DeepSeek-v3模型 参数汇总表\n",
    "\n",
    "| 参数名                 | 类型                 | 必填/可选  | 默认值       | 说明                                                                                     |\n",
    "|------------------------|----------------------|------------|--------------|------------------------------------------------------------------------------------------|\n",
    "| **model**              | string               | 必填       | 无           | 指定要使用的模型 ID，例如 `gpt-4o` 或 `gpt-4o-mini`。                                     |\n",
    "| **store**              | boolean or null      | 可选       | false        | 是否存储本次对话的输出，供模型精炼或评估产品使用。                                         |\n",
    "| **metadata**           | object or null       | 可选       | null         | 开发者自定义的标签和值，用于过滤仪表盘中的补全结果。                                        |\n",
    "| **frequency_penalty**  | number or null       | 可选       | 0            | 数值在 `-2.0` 到 `2.0` 之间，正值减少重复生成内容的可能性。                                |\n",
    "| **logit_bias**         | map                  | 可选       | null         | 调整某些特定 tokens 出现的可能性，值在 `-100` 到 `100` 之间。                             |\n",
    "| **logprobs**           | boolean or null      | 可选       | false        | 是否返回生成的每个 token 的对数概率。                                                      |\n",
    "| **top_logprobs**       | integer or null      | 可选       | null         | 指定返回最有可能出现的前几个 tokens 及其概率，需开启 `logprobs`。                          |\n",
    "| **max_completion_tokens** | integer or null    | 可选       | null         | 指定模型生成的最大 token 数，包括可见文本和推理 tokens。                                      |\n",
    "| **n**                  | integer or null      | 可选       | 1            | 每个输入生成的对话补全选项数量，值越大，生成的回复越多。                                     |\n",
    "| **presence_penalty**    | number or null       | 可选       | 0            | 数值在 `-2.0` 到 `2.0` 之间，正值鼓励生成新的主题和内容。                                   |\n",
    "| **response_format**     | object               | 可选       | null         | 指定生成结果的格式，可以设置为 `json_schema` 以确保结构化输出，或 `json_object` 用于 JSON 格式。 |\n",
    "| **seed**               | integer or null      | 可选       | null         | 保持生成的一致性，重复相同请求将尽量生成相同的结果。                                         |\n",
    "| **service_tier**        | string or null       | 可选       | auto         | 指定服务延迟等级，适用于付费订阅用户，默认为 `auto`。                                       |\n",
    "| **stop**               | string / array / null | 可选       | null         | 最多指定 4 个序列，API 遇到这些序列时会停止生成进一步的 tokens。                             |\n",
    "| **stream**             | boolean or null      | 可选       | false        | 是否启用流式响应，若启用，生成的 tokens 将逐步返回。                                         |\n",
    "| **stream_options**      | object or null       | 可选       | null         | 流式响应的选项，仅当 `stream` 为 `true` 时设置。                                             |\n",
    "| **temperature**        | number or null       | 可选       | 1            | 控制生成输出的随机性，值越高生成的文本越随机。建议调整此值或 `top_p`，而不是同时调整。         |\n",
    "| **top_p**              | number or null       | 可选       | 1            | 使用核采样方法，选择最有可能的 tokens，总概率达到 `top_p` 百分比。建议与 `temperature` 二选一。 |\n",
    "| **tools**              | array                | 可选       | null         | 模型可以调用的工具列表，目前仅支持函数调用。                                                 |\n",
    "| **user**               | string               | 可选       | null         | 表示最终用户的唯一标识符，用于监控和检测滥用行为。                                           |\n",
    "\n",
    "---\n",
    "\n",
    "### 参数解释：\n",
    "\n",
    "1. **模型和输出相关参数**：\n",
    "   - `model` 是必填参数，决定使用哪个模型（如 `deepseek-chat ` 或 `deepseek-code`）。\n",
    "   - `store` 控制是否存储生成的对话结果，便于后续模型训练或评估。\n",
    "   - `metadata` 用于添加开发者自定义的标签，便于在仪表盘中过滤补全结果。\n",
    "   - `max_completion_tokens` 和 `n` 控制生成内容的数量和长度，帮助管理生成成本。\n",
    "\n",
    "2. **生成行为控制**：\n",
    "   - `frequency_penalty` 和 `presence_penalty` 都用于影响生成结果的内容重复度和新颖性。\n",
    "   - `logit_bias` 是用于调整特定 token 出现概率的高级控制工具。\n",
    "   - `temperature` 和 `top_p` 通过不同的方式控制生成结果的随机性，建议选其一进行调整。\n",
    "\n",
    "3. **高级功能**：\n",
    "   - `logprobs` 和 `top_logprobs` 用于返回每个 token 的概率信息，适合对模型输出进行更细粒度分析。\n",
    "   - `stream` 启用后会实时返回生成的结果，适用于需要逐步展示内容的场景。\n",
    "   - `tools` 允许模型调用外部工具（如函数），适用于扩展模型的功能。\n",
    "\n",
    "4. **服务和用户相关参数**：\n",
    "   - `service_tier` 控制服务的延迟和稳定性，适合高性能要求的付费用户。\n",
    "   - `user` 用于标识最终用户，有助于监控使用行为，防止滥用。\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
