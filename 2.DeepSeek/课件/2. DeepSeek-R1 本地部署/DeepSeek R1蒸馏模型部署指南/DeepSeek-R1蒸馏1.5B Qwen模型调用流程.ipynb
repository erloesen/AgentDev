{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fb016c-b355-44a2-86bc-86ecb2336bfc",
   "metadata": {},
   "source": [
    "### DeepSeek-R1蒸馏1.5B Qwen模型调用流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8787d251-8187-402e-b9cf-f127614b4fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/R1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modelscope import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa01f682-dd14-4354-8e72-5309c40e6ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入模型下载地址\n",
    "model_name = \"./DeepSeek-R1-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a66b7b-6cec-4804-a492-a3b28b6d22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化预训练模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9521f3-a1af-443b-93c6-81e790e77dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建消息\n",
    "prompt = \"你好，好久不见，请介绍下你自己。\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一名助人为乐的助手。\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334f8ac6-b88f-492a-a083-6517184aa8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03557c37-c4d6-4fa9-9511-9e7b0c39df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# 创建回复\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ffbba26-48a4-4263-b69d-da65ff528376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "好，用户说“你好，好久不见，请介绍下你自己。”我应该先感谢他，然后介绍自己。我需要保持礼貌和亲切，所以开头可以用“你好！很高兴见到你。”然后简要介绍一下自己，比如是人工智能助手，专注于帮助用户解决问题。这样既介绍了自己，又回应了用户的需求。\n",
      "\n",
      "接着，我应该邀请他继续交流，用“如果需要更多帮助，欢迎随时提问。”这样可以保持对话的流畅性，让用户觉得我们愿意继续帮助。\n",
      "\n",
      "整体语气要自然，不要太生硬，让用户感觉被重视。最后，检查一下有没有遗漏的部分，确保信息完整，没有多余的内容。\n",
      "\n",
      "这样，整个回复就完成了，既回答了用户的问题，又表现出对他的关心和帮助意愿。\n",
      "</think>\n",
      "\n",
      "你好！很高兴见到你。我是人工智能助手，专注于帮助您解决问题。如果需要更多帮助，欢迎随时提问。\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95af7bc-d5b7-4b36-9fad-dc443c0cfcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2c2b9-245e-4dfa-99e2-310e7d0b5e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceaf157-3048-4e61-843b-e1e0c9f5945b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc197c3-855b-4a38-8b6b-96688f7a6e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python R1)",
   "language": "python",
   "name": "r1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
