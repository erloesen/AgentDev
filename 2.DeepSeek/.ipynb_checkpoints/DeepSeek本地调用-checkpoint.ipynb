{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce854f73-0db3-4a38-87b1-eb49bebeafc1",
   "metadata": {},
   "source": [
    "# DeepSeek相关"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01dd41-ed80-49b5-b5f8-ce40daa1b28e",
   "metadata": {},
   "source": [
    "## 1. 开源情况介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc5dc63-cc87-467c-a3d0-a8c22e74756c",
   "metadata": {},
   "source": [
    "https://github.com/deepseek-ai/DeepSeek-V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaee29a-6d21-4122-9f54-d05900850419",
   "metadata": {},
   "source": [
    "https://huggingface.co/deepseek-ai/DeepSeek-V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3a416-c1ae-46d5-8d19-4f96a67e5790",
   "metadata": {},
   "source": [
    "https://www.modelscope.cn/models/deepseek-ai/DeepSeek-V3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36613bf8-6a96-4231-8392-916f8f8f5ef1",
   "metadata": {},
   "source": [
    "项目工程中，inference是模型代码，其中有几个组件需要关注：\n",
    "* conver.py：模型格式转化，修改模型基本架构\n",
    "* fp8_cast_bf16.py：将FP8权重转为BF16格式\n",
    "* generate.py：用于生成文本的实例程序，支持交互式和批量生成\n",
    "* kernel.py：量化和矩阵乘法操作，使用Triton加速，针对FP8精度进行了优化\n",
    "* model.py：定义DeepSeekv3模型架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4855d3-4d45-47c9-bf1e-1e144f7fac22",
   "metadata": {},
   "source": [
    "## 2. 本地部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d0503-f978-49e7-b6a8-9502f41b2148",
   "metadata": {},
   "source": [
    "### 2.1 原生方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1abee08-9214-4982-b161-9b5f0cc192b1",
   "metadata": {},
   "source": [
    "克隆deepseek项目后，需要下载权重文件，推荐使用模搭社区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb97092-2d7e-4e7d-8c32-6063a65882fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install modelscope\n",
    "mkdir ./deepseek\n",
    "modelscope download --model OPEA/DeepSeek-V3-int4-sym-gptq-inc --local_dir ./deepseek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d005405-1c50-4cc3-b186-ae959d13d88f",
   "metadata": {},
   "source": [
    "下载的是int4的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9ae56-9bab-40ee-88f0-bcedf8c17f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modelscope import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "model_name = \"./deepseek\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356885b-8a50-492d-a389-ccbee58a8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"user\", \"content\":\"你好，好久不见，请介绍下你自己！\"}\n",
    "]\n",
    "input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_tensor.to(model.device), max_new_tokens=100)\n",
    "result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611cd61-4ea0-4cf7-8510-506b8781b0d0",
   "metadata": {},
   "source": [
    "### 2.2 SGLang方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1e0ce-fd85-472e-b01e-889ecb7feaed",
   "metadata": {},
   "source": [
    "https://github.com/sgl-project/sglang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7a7ff-33a1-45d3-89e0-ef53ff78aad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6343667-1835-49e7-a418-8e37e7299b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575a64d-7354-4aec-92fb-816840c2364e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28146a-20bf-4669-88fb-4105c06599ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fcde3-d76d-46bf-afd7-2aa4f26f8712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22bd7b-6ba4-498b-9654-3213fe1691c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c4fd4-8cf3-4c3d-b5b1-41e3aa98f18c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c8ec7-ada5-4fe5-9f2f-4a62c60c7821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171bde9-30bb-4cc5-8e91-8af020215c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
