{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e74bf1-7c09-49a4-9c48-ba638ac59a28",
   "metadata": {},
   "source": [
    "# 1. LangGraph底层原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325934ee-8198-4721-9055-3b0990587420",
   "metadata": {},
   "source": [
    "## 1.1 为什么用LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de79d0b-afd4-4ca1-928e-ec1ef32b9162",
   "metadata": {},
   "source": [
    "与仅限于使用`GPT`系列模型的`Assistant API`框架不同，`LangGraph`是一个适用范围更广的`AI Agent`开发框架。在**大模型的支持方面**，`LangGraph`不仅支持`GPT`系列，还兼容其他多种在线或开源模型，例如 `glm4`、`llama3`和`Qwen`等，可以说热门的大模型均可以接入到该框架中进行`AI Agent`应用程序的开发。而关于**大模型的接入方式**，我们既可以通过传统的`openai api`等原生方式将大模型集成到`LangGraph`构建的`AI Agent`流程中，也可以利用`ollma`、`vllm`等大模型推理加速库，实现更加便捷和高效的集成。除此之外，**在`AI Agent`的构建范式上**，`LangGraph`不仅提供了预配置的`ReAct`代理机制，还支持更多自定义的如`Planning`策略的接入，以满足不同应用场景的需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2f205-9728-4bdf-bf47-36b84cfe9ed9",
   "metadata": {},
   "source": [
    "从三大方面来看，`LangGraph`的**高度自主性和开放性**确实让它在功能和灵活性上相较于`Assistant API`具有明显的优势。但需要注意的是，这种自主性和可扩展性也带来了更高的复杂性和开发要求。使用`LangGraph`意味着**开发者需要进行较多的自主开发工作**。此外，`LangGraph`框架的底层架构复杂非常复杂，这直接导致了`LangGraph`的学习和使用门槛相对较高。并且，经过我们长时间的探索和实践会明显发现，即使是经过多轮的尝试和优化，使用`LangGraph`构建的`AI Agent`应用程序的效果也很难超过用`Assistant API`几行代码就能实现的效果。所以，我们要想掌握和应用`LangGraph`，势必要投入更多的时间和精力。这是大家在开始学习前必须做好的心理准备。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6463a7b-09ac-4c5b-a576-3b0d31bf7497",
   "metadata": {},
   "source": [
    "## 1.2 什么是LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ccb62-d453-440d-aa01-2ec6679ea6be",
   "metadata": {},
   "source": [
    "从名字上看，应该是和`Langchain`有着非常紧密的关系，而事实也确实是这样。**因为`LangGraph` 就是以 `LangChain` 表达式语言为基础而构建起来的用于开发`AI Agent`的一个框架**。所以我们上面提到的关于`LangGragh`在大模型的支持、接入和`AI Agent`构建方面的优势，都可以非常自然的从`LangChain`中迁移过来。从大模型技术发展的角度来看，**大模型本身是无法采取任何行动的，它们的作用只是用来输出文本**，即接收用户的输入并对这些输入给出响应。为了更好和更高效的做到这件事情，`langchain`项目在2023年就建立起了非常活跃的社区来定义大模型的应用规范。发展到现在，`LangChain`现在也发布了3个大的版本，而**在其整个的构建体系中，一个重要用例是创建代理**。在`LangChain`中，构建`AI Agent`的底层架构如下图所示：👇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb64253-c381-4517-a2c8-9d3c7348cf6f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://snowball101.oss-cn-beijing.aliyuncs.com/img/202404031102489.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b5d130-8a43-4af8-8cbc-4bbfc6664b6d",
   "metadata": {},
   "source": [
    "首先，`langChain`框架中的`AI Agent`设计，在内部结构会将其分为三个核心的组件，分别是`Agent`，`Message`和`Toolkits`。每个`Agent`组件一般会由大语言模型 + 提示 + 输出解析器构成，形成一个`Chain`去处理用户的输入。而`Agent`能够处理的输入主要来源于三个方面：`input`代表用户的原始输入，`Model Response`指的是模型对某一个子任务的响应输出，而`History`则能携带上下文的信息。其输出部分，则链接到实际的工具库，需要调用哪些工具，将由经过`Agent`模块后拆分的子任务来决定。大模型调用外部函数会分为两个过程：识别工具和实际执行。在Message -> Agent -> Toolkits 这个流程中，负责的是将子任务拆解，然后根据这些子任务在工具库中找到相应的工具，提取工具名称及所需参数，这个过程可以视作一种“静态”的执行流程。而将这些决策转化为实际行动的工作，则会交给`AgentExecutor`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb154c-a0fa-46ad-927d-37df5aa2cb7f",
   "metadata": {},
   "source": [
    "在LangChain的`AI Agent`实际架构中，`Agent`的角色是接收输入并决定采取的操作，但它本身并不直接执行这些操作。这一任务是由`AgentExecutor`来完成的。将`Agent`（决策大脑）与`AgentExecutor`（执行操作的Runtime）结合使用，才构成了完整的`Agents`（智能体），**其中`AgentExecutor`负责调用代理并执行指定的工具**，以此来实现整个智能体的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b09594-0a8c-4e67-88ba-62af2de5f292",
   "metadata": {},
   "source": [
    "## 1.3 LangGraph底层原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7d192-f16c-4578-90e7-5640f6ae0b2e",
   "metadata": {},
   "source": [
    "`LangChain`发展至现在，仍然是构建大语言模型应用程序的前沿框架之一。特别是在最新发布的`v0.3`版本中，已经基本完成了由传统类到表达式语言(LCEL)的重要过渡，给开发者带来的直接利好就是**定义和执行分步操作序列（也称为链）会更加简单**。用更专业的术语来说，**使用`LangChain` 构建的是 DAG（有向无环图）**。而之所以会出现`LangGraph`框架，根本原因是在于随着AI应用（特别是AI Agent）的发展，**对于大语言模型的使用不仅仅是作为执行工具，而更多作为推理引擎的需求在日益增长**。这种转变带来的是更多的重复（循环）和复杂条件的交互需求，这就导致**基于`LCEL`的线性序列构建方式在构建更复杂、更智能的系统时显示出了明显的局限性**。如下所示的代码就是在`LangChain`中通过`LECL`表达式语言构建`Chain`的一种最简单的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c7148-29c8-4136-81d2-604da58b9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dashscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a39403-a9dd-48fb-891b-b28c939d2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../config/.env')\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = os.getenv(\"QWEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ad8247-1006-4caf-9034-d42ce5203be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0dc7b91-2a75-4220-9d98-662f2d095781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我热爱编程。', additional_kwargs={}, response_metadata={'model_name': 'qwen-plus', 'finish_reason': 'stop', 'request_id': 'a16d0891-b001-9a09-a834-c367b02f2e8c', 'token_usage': {'input_tokens': 32, 'output_tokens': 4, 'total_tokens': 36, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--0d45f1aa-4a63-420e-a62f-79e76d88e09f-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatTongyi(model=\"qwen-plus\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant that translates {input_language} to {output_language}.\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Chinese\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e199089-4857-43c3-8d2c-9db9e0e77c55",
   "metadata": {},
   "source": [
    "反观`LangGraph`，顾名思义，`LangGraph` 在图这个概念上有很大的侧重，**它的出现就是`要解决线性序列的局限性问题，而解决的方法就是循环图`**。在`LangGraph`框架中，**用图取代了`LangChain`的`AgentExecutor`（代理执行器），用来管理代理的生命周期并在其状态内将暂存器作为消息进行跟踪，增加了以循环方式跨各种计算步骤协调多个链或参与者的功能。**这就与 `LangChain` 将代理视为可以附加工具和插入某些提示的对象不同，对于图来说，意味着**我们可以从任何可运行的功能或代理或链作为一个程序的起点**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234b876-bac5-4c03-b121-67a3deaa5b87",
   "metadata": {},
   "source": [
    "在以图构建的框架中，**任何可执行的功能都可以作为对话、代理或程序的启动点**。这个启动点可以是大模型的 `API` 接口、基于大模型构建的 `AI Agent`，通过 `LangChain` 或其他技术建立的线性序列等等，即下图中的 \"Start\" 圆圈所示。无论哪种形式，它都首先处理用户的输入，并决定接下来要做什么。下图展示了在 `LangGraph` 概念下，最基本的一种代理模型：👇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b1d6e-620c-4677-97bb-0dcf8bf40ba0",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/1011002.png\" width=50%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17195c9c-94e2-4d30-94b7-25896fe19b2c",
   "metadata": {},
   "source": [
    "**在启动点定义的可运行功能会根据收到的输入决定是否进行检索以及如何响应**。比如在执行过程中，如果需要检索信息，则可以利用搜索工具来实现，比如`Web Search`（网络搜索）、`Query Database`（查询数据库）、`RAG`等获取必要的信息（图中的 \"Action\" 圆圈）。接下来，再使用一个大语言模型（LLM）处理工具提供的信息，结合用户最初传入的初始查询，生成最终的响应（图中的 \"LLMs\" 圆圈）。最终，这个响应被传递至终点节点（图中的 \"End\" 圆圈）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b1828-fd02-48c5-92bb-e40b36a1931a",
   "metadata": {},
   "source": [
    "上图所示的流程就是在`LangGraph`概念中一个非常简单的代理构成形式。关键且必须清楚的概念是：在这里，**每个圆圈代表一个“节点”（Nodes），每个箭头表示一条“边”（Edges）。因此，在 `LangGraph` 中，无论代理的构建是简单还是复杂，它最终都是由节点和边通过特定的组合形成的图。这样的构建形式形成的工作流原理就是：当每个节点完成工作后，通过边告诉下一步该做什么，所以也就得出了：`LangGraph`的底层图算法就是在使用消息传递来定义通用程序。当节点完成其操作时，它会沿着一条或多条边向其他节点发送消息。然后，这些接收节点执行其功能，将结果消息传递给下一组节点，然后该过程继续。如此循环往复。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573e68a-1cbe-4ac7-bc08-4c76624c016d",
   "metadata": {},
   "source": [
    "在这个示例中，我们将`AI Agent`定义为应用程序的起点。**构建`AI Agent`代理通常涉及配置一个或多个工具**，否则构建它就没有太大的意义，因为如果仅仅是针对用户的问题直接做响应，即使问题很复杂，我们也可以直接通过提示词来引导大模型进行推理（参考`OpenAI`的 `o1`推理模型）。那么当`AI Agent`包含一些工具时，它是通过函数调用功能使用这些工具，而不是直接执行这些工具。所以当用户输入的原始问题经过`AI Agent`处理的时候，一般会出现以下两种情况：\n",
    "1. 如果不需要调用任何工具，`AI Agent` 会直接提供一个针对用户问题的自然语言响应。例如：\n",
    "   - 用户：你好，请你介绍一下你自己。\n",
    "   - AI Agent：你好，我是一个人工智能助手，可以帮助你解决问题。\n",
    "2. 如果需要调用工具，则输出将是一个特定格式的 JSON 输出，指示进行特定的函数调用。例如：\n",
    "   - 输出示例：function': {'arguments': '{\"query\":\"什么是快乐星球？\"}','name': 'web_search'},'type': 'function'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099259d-1a8a-477d-8dcf-6e32ef6d01e7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/101103.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999a6ed-3b0a-48c3-8d9c-54c92817e410",
   "metadata": {},
   "source": [
    "经过第一个节点后（Agent），如果`AI Agent`认为需要调用某个函数，它会确定使用哪个工具以及传递哪些参数。假设有多个工具可选的情况下，`Action` 节点将呈现多条可能的路径供选择。如何选择呢？这时候，`LangGraph` 引入了一个**称为“条件边”的组件。条件边根据是否满足特定条件来决定走哪条路径，例如，代理可能需要决定是使用搜索工具还是直接生成最终答案**。为了管理这些决策，则使用了一个类似于 `if-else` 语句的结构，称为`Router`。基于`Router`的决策，代理可能会导向“搜索节点”以执行搜索操作并返回原始文本，或者直接前往“最终答案节点”以获取格式化后的自然语言响应。**如果选择了搜索路径，获取的答案文本还需通过另一个大语言模型进行处理，以生成用户可以理解的响应；若选择了直接回答，则可以使用一个专门的工具来格式化输出**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5d0e8-eaa0-4da8-890f-4cbef0c28e34",
   "metadata": {},
   "source": [
    "在 `LangGraph` 框架中，`Router` 使用 `if..else` 的形式来决定路径，主要通过以下三种方式实现：\n",
    "- 提示工程：指示大模型以特定格式做出回应。\n",
    "- 输出解析器：使用后处理从大模型响应中提取结构化数据。\n",
    "- 工具调用：利用大模型的内置工具调用功能来生成结构化输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee1e4ad-0b95-42a9-93ee-a147d44dbfb1",
   "metadata": {},
   "source": [
    "更进一步地，我们现在知道了`LangGraph`通过组合`Nodes`和`Edges`去创建复杂的循环工作流程，通过消息传递的方式串联所有的节点形成一个通路。**那么维持消息能够及时的更新并向该去的地方传递，则依赖`langGraph`构建的`State`概念。** 在`LangGraph`构建的流程中，每次执行都会启动一个状态，图中的节点在处理时会传递和修改该状态。这个状态不仅仅是一组静态数据，而是由每个节点的输出动态更新，然后影响循环内的后续操作。如下所示：👇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec041b6a-0c89-4238-baa3-c8f88bb89ac3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/101104.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1dfdd-8bf2-473c-99d7-867d99daf366",
   "metadata": {},
   "source": [
    "**此谓共享状态**。共享状态是指在执行期间在图内的节点之间传递的数据或信息。**`LangGraph`允许节点在图上执行时时通过共享和更新此公共状态来进行交互**。这种共享状态使节点能够根据它们共同维护的数据进行通信、交换信息并影响彼此的行为。通过利用共享状态， `LangGraph`才能够促进节点间操作的协调和同步，允许动态交互和创建复杂的工作流程，其中节点可以协作并根据可用的共享信息做出决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a145e29-2905-4ab5-97ca-0725af1102b7",
   "metadata": {},
   "source": [
    "从`LangGraph`官方的定义看，该框架是一个**用于使用大模型构建有状态、多参与者应用程序的库，可以创建代理和多代理工作流程**。而其官方自己总结的`LangGraph`的优势则是：\n",
    "\n",
    "- **循环和分支**：在应用程序中实现循环和条件。\n",
    "- **持久性**：在图中的每个步骤之后自动保存状态。随时暂停和恢复图形执行，以支持错误恢复、人机交互工作流程、时间旅行等。\n",
    "- **人机交互**：中断图形执行以批准或编辑代理计划的下一个操作。\n",
    "- **流支持**：流输出由每个节点生成（包括令牌流）。\n",
    "- **与 LangChain 集成**：LangGraph 与LangChain和LangSmith无缝集成（但不需要它们）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c707edfd-3191-483e-974c-fe5c13b85b04",
   "metadata": {},
   "source": [
    "## 1.4 LangGraph底层源码解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a155d0-ab79-4968-b16d-91d5cfbe43e8",
   "metadata": {},
   "source": [
    "### 1.4.1 Graph基类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a23110-2a35-4f97-8cd9-c0fa75975c35",
   "metadata": {},
   "source": [
    "对于任意一个简单或者复杂的图来说，都是基于`Graph`类来构建和管理图结构的。在`Graph`类中允许添加节点、边，并定义节点间的动态流转逻辑。如下是`Graph`类的主要组成部分和功能："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf8dc1b-2858-4def-9c89-06963404af02",
   "metadata": {},
   "source": [
    "> Class Graph ：https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79d4f3a-5635-4f1c-8215-402bb3cbe76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Any, Callable, Dict, Optional, Set, Tuple, Union, Awaitable, Hashable\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self) -> None:\n",
    "        self.nodes: Dict[str, Any] = {}  # 一个字典，用于存储图中的所有节点。每个节点可以是一个字符串标识或者是一个可调用对象\n",
    "        self.edges: Set[Tuple[str, str]] = set()  # 一个集合，用来存储图中所有的边，边由一对节点名称组成，表示从一个节点到另一个节点的直接连接。\n",
    "        self.branches: defaultdict = defaultdict(dict)  # 一个默认字典，用于存储条件分支，允许从一个节点根据特定条件转移到多个不同的节点。\n",
    "        self.support_multiple_edges = False  # 一个布尔值，指示图是否支持同一对节点间的多条边。\n",
    "        self.compiled = False    #  一个布尔值，表示图是否已经被编译。编译是指图的结构已经设置完毕，准备进行执行。\n",
    "\n",
    "    @property\n",
    "    def _all_edges(self) -> Set[Tuple[str, str]]:\n",
    "        \"\"\"\n",
    "        获取所有边的数据。\n",
    "        \"\"\"\n",
    "        return self.edges\n",
    "\n",
    "    def add_node(self, node: Union[str, Callable], action: Optional[Callable] = None, *, metadata: Optional[Dict[str, Any]] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        添加一个新节点到图中。节点可以有附加的元数据，这些元数据存储在节点的字典中。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_edge(self, start_key: str, end_key: str) -> 'Graph':\n",
    "        \"\"\"\n",
    "        在图中添加一条边，连接两个指定的节点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_conditional_edges(self, source: str, path: Callable, path_map: Optional[Dict[Hashable, str]] = None, then: Optional[str] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        添加一个条件边，允许在执行时根据某个条件从一个节点动态地转移到一个或多个节点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_entry_point(self, key: str) -> 'Graph':\n",
    "        \"\"\"\n",
    "        设置图的入口点，即定义图执行的起始节点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_conditional_entry_point(self, path: Callable, path_map: Optional[Dict[Hashable, str]] = None, then: Optional[str] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        设置一个条件入口点，允许根据条件动态决定图的起始执行点。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_finish_point(self, key: str) -> 'Graph':\n",
    "        \"\"\"\n",
    "        设置结束点，定义图执行到此节点时将停止。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def validate(self, interrupt: Optional[Set[str]] = None) -> 'Graph':\n",
    "        \"\"\"\n",
    "        验证图的结构是否正确，确保所有节点和边的定义都符合逻辑和图的规则。\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def compile(self, checkpointer=None, interrupt_before: Optional[Set[str]] = None, interrupt_after: Optional[Set[str]] = None, debug: bool = False) -> 'Graph':\n",
    "        \"\"\"\n",
    "        编译图，确认图的结构合法且可执行后，准备图以供执行。\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a98f3-cca5-4343-84b6-43a96c4debe6",
   "metadata": {},
   "source": [
    "从源码中可以看出，`Graph`该类提供了丰富的方法来控制图的编译和执行，使其适用于需要复杂逻辑和流程控制的应用场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d4222-e861-4913-a41f-0ca416ebb590",
   "metadata": {},
   "source": [
    "### 1.4.2 GraphState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa7f00-ef49-4d21-b3e8-f3b5409ab7ed",
   "metadata": {},
   "source": [
    "**定义图时要做的第一件事是定义图的`State`**。状态表示会随着图计算的进行而维护和更新的上下文或记忆。它用来确保图中的每个步骤都可以访问先前步骤的相关信息，从而可以根据整个过程中积累的数据进行动态决策。这个过程通过状态图`StateGraph`类实现，它继承自 `Graph` 类，这意味着 `StateGraph` 会使用或扩展基类的属性和方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631bb3b-215c-43a6-bacd-998b49f5f834",
   "metadata": {},
   "source": [
    "> Class StateGraph：https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed4d637-8a11-4c79-a217-02856c75e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Any, Callable, Dict, Optional, Set, Tuple, Type, Union\n",
    "\n",
    "class StateGraph(Graph):\n",
    "\n",
    "    \"\"\"StateGraph 是一个管理状态并通过定义的输入和输出架构支持状态转换的图。\"\"\"\n",
    "    def __init__(self, state_schema: Optional[Type[Any]] = None, config_schema: Optional[Type[Any]] = None) -> None:\n",
    "        super().__init__()\n",
    "        self.state_schema = state_schema      # 一个可选的类型参数，定义图状态的结构。这是用于定义和验证图中节点处理的状态数据的模式。\n",
    "        self.config_schema = config_schema    # 一个可选的类型参数，用于定义配置的结构。这可以用于定义和验证图的配置参数。\n",
    "        self.input: Optional[Type[Ang]] = None\n",
    "        self.output: Optional[Type[Ang]] = None\n",
    "\n",
    "    def add_node(self, node: Union[str, Callable], action: Optional[Callable] = None, *, metadata: Optional[Dict[str, Any]] = None) -> 'StateGraph':\n",
    "        \"\"\"向图中添加一个新节点。节点可以是一个具名字符串或一个可调用对象（如函数）, 如果node是字符串，则action应为与节点关联的可调用动作。\"\"\"\n",
    "        pass\n",
    "\n",
    "    def add_edge(self, start_key: str, end_key: str) -> 'StateGraph':\n",
    "        \"\"\"在图中添加一条边，连接两个节点。\"\"\"\n",
    "        pass\n",
    "\n",
    "    def compile(self) -> 'CompiledStateGraph':\n",
    "        \"\"\"编译图，将其转换成可运行的形式。包括验证图的完整性、预处理数据等。\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3625a-f85f-4c14-aaf3-64ea3ffba85a",
   "metadata": {},
   "source": [
    "- **什么是图的模式**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fef5ae-fc8e-4c17-81c2-28cf10a09a6e",
   "metadata": {},
   "source": [
    "**默认情况下，`StateGraph`使用单模式运行，这意味着在图中的任意阶段都会读取和写入相同的状态通道，所有节点都使用该状态通道进行通信**。除此之外，在某些情况下如果希望对图的状态有更多的控制，比如：\n",
    "- 内部节点可以传递图的输入/输出中不需要的信息。\n",
    "- 对图使用不同的输入/输出模式。例如，输出可能仅包含单个相关输出键。\n",
    "\n",
    "`LangGraph`的底层实现上提供了多种不同图模式的支持，这可以通过`state_schema`来进行灵活的指定。不过关于自定义的图模式，因为涉及到更多的基础概念，我们将在课程的后半部分在展开详细的介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a8d23-7db6-4ba5-b249-57f5fbdb6c35",
   "metadata": {},
   "source": [
    "首先来看图的单模式。任何模式都包含输入和输出，输入模式需要确保提供的输入与预期结构匹配，而输出模式根据定义的输出模式过滤内部数据以仅返回相关信息。而这个预期结构的校验，由`TypedDict`工具来限定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4297ff9-d068-4b81-9cf6-394b0315edff",
   "metadata": {},
   "source": [
    "- **TypeDict** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9a170-f2ad-4daf-918d-a8c4c9cbe838",
   "metadata": {},
   "source": [
    "`TypedDict` 是 `Python` 类型注解系统中的一个工具，它**允许为字典中的键指定期望的具体类型**。在 `Python` 的 `typing` 模块中定义，通常用于增强代码的可读性和安全性，特别是在字典对象结构固定且明确时。示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f938a08a-c100-491c-a882-5c4f6e9dbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending email to Alice at alice@example.com\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class Contact(TypedDict):\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "def send_email(contact: Contact) -> None:\n",
    "    print(f\"Sending email to {contact['name']} at {contact['email']}\")\n",
    "\n",
    "# 使用定义好的 TypedDict 创建字典\n",
    "contact_info: Contact = {\n",
    "    'name': 'Alice',\n",
    "    'email': 'alice@example.com',\n",
    "    'phone': '123-456-7890'\n",
    "}\n",
    "\n",
    "send_email(contact_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade8b5cf-6b53-494a-bab0-be41aa14765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492ed34-c575-4206-b9c1-b79899ed8521",
   "metadata": {},
   "source": [
    "接下来，创建一个 `StateGraph` 对象，使用 `OverallState` 作为其状态定义，同时指定了输入和输出类型分别为 `InputState` 和 `OutputState`，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c708ac-300e-42c8-9e52-1460d37d4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9fcd38-4ccf-4efa-bd54-b5eaadc99dd1",
   "metadata": {},
   "source": [
    "创建 `builder` 对象后，相当于构建了一个图结构的框架。接下来的步骤是向这个图中添加节点和边，完善和丰富图的内部执行逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7682c45-b48e-40eb-a63d-76805acdc70e",
   "metadata": {},
   "source": [
    "### 1.4.3 Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d9e44-601c-4f29-b59a-2ca73d1c828d",
   "metadata": {},
   "source": [
    "在 `LangGraph` 中，节点是一个 `python` 函数（sync 或async ），接收当前`State`作为输入，执行自定义的计算，并返回更新的`State`。所以其中第一个位置参数是`state` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9678c94-5086-4bc7-b256-31a035bd3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state:InputState):\n",
    "    print(\"我是一个AI Agent。\")\n",
    "    return\n",
    "\n",
    "def action_node(state:InputState):\n",
    "    print(\"我现在是一个执行者。\")\n",
    "    return {\"answer\":\"我现在执行成功了\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09d5fb-be59-4533-a455-1b439956ec55",
   "metadata": {},
   "source": [
    "定义好了节点以后，我们需要使用`add_node`方法将这些节点添加到图中。在将节点添加到图中的时候，可以自定义节点的名称。而如果不指定名称，则会为自动指定一个与函数名称等效的默认名称。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d308c2-1814-48ba-8c73-a9c1c4b15dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2264fd5bc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_node(\"agent_node\", agent_node)\n",
    "builder.add_node(\"action_node\", action_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa017de0-e497-4944-9478-553af41d5584",
   "metadata": {},
   "source": [
    "现在有了图结构，并且图结构中也存在两个孤立的节点`agent_node`和`action_node`，接下来我们要做的事就是需要将图中的节点按照我们所期望的方式进行连接，这需要用到的就是`Edges` - 边。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb30230-aab2-43c9-8e5c-958e9c516fe1",
   "metadata": {},
   "source": [
    "### 1.4.4 Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888651e-b197-4cc8-aef4-a22c62aaac3f",
   "metadata": {},
   "source": [
    "Edges（边）用来定义逻辑如何路由以及图何时开始与停止。这是代理工作以及不同节点如何相互通信的重要组成部分。有几种关键的边类型：\n",
    "- 普通边：直接从一个节点到下一个节点。\n",
    "- 条件边：调用函数来确定下一个要转到的节点。\n",
    "- 入口点：当用户输入到达时首先调用哪个节点。\n",
    "- 条件入口点：调用函数来确定当用户输入到达时首先调用哪个节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993fb5e0-3f52-40ac-840a-f2687a188b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2264fd5bc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "builder.add_edge(START, \"agent_node\")\n",
    "builder.add_edge(\"agent_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8edb6-7373-4bc8-8085-828a9acb7be5",
   "metadata": {},
   "source": [
    "最后，通过`compile`编译图。在编译过程中，会对图结构执行一些基本检查（如有没有孤立节点等）。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3abbdb12-3a9a-400d-9637-cc8df84bbc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488aef8-51d3-4515-b6d7-c6feb0f12264",
   "metadata": {},
   "source": [
    "### 1.4.5 Graph的调用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac3dd3b-4e9f-4890-b5ec-222d54627e96",
   "metadata": {},
   "source": [
    "要调用图中的方法，可以使用 `invoke` 方法。示例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b844af7-505c-4de1-8a14-af4ae804eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI Agent。\n",
      "我现在是一个执行者。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '我现在执行成功了'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"你好\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb1c5c-0cee-42f0-bb78-a594f8d72a8a",
   "metadata": {},
   "source": [
    "在这个过程中，我们将`state: InputState`作为输入模式传递给`agent_node`，在传递到`action_node`，最后由`action_node`传递到`END`节点。节点之间通过边是已经构建了完整的通路，那么如果我们想要传递每个节点的状态信息，则可以稍加修改即可实现。对于图模式，我们的定义方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b61bc6e-c38b-4b93-8c28-df0a3ace40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个更全面的字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass\n",
    "\n",
    "def agent_node(state: InputState):\n",
    "    print(\"我是一个AI Agent。\")\n",
    "    return {\"question\": state[\"question\"]}\n",
    "\n",
    "def action_node(state: InputState):\n",
    "    print(\"我现在是一个执行者。\")\n",
    "    step = state[\"question\"]\n",
    "    return {\"answer\": f\"我接收到的问题是：{step}，读取成功了！\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dc6cf27-1bd3-4016-b1b3-7199de08bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明确指定它的输入和输出数据的结构或模式\n",
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"agent_node\", agent_node)\n",
    "builder.add_node(\"action_node\", action_node)\n",
    "\n",
    "# 添加便\n",
    "builder.add_edge(START, \"agent_node\")\n",
    "builder.add_edge(\"agent_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "035b9bab-5799-4af4-bc94-80e097812e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI Agent。\n",
      "我现在是一个执行者。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '我接收到的问题是：今天的天气怎么样？，读取成功了！'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"今天的天气怎么样？\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee0ffc-676d-4d1e-bc93-e14db32ac30d",
   "metadata": {},
   "source": [
    "不同节点间能够传递信息的原因是因为节点可以写入图状态中的任何状态通道。图状态是初始化时定义的状态通道的并集，而我们定义的状态通道包含了`OverallState`以及过滤器`InputState`和`OutputState` 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b13007-b441-41e1-92cc-245cdcf0e195",
   "metadata": {},
   "source": [
    "上述代码实际上中途没有更新state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84176f4c-36e8-4a40-88fa-dc0e1244bd6c",
   "metadata": {},
   "source": [
    "## 1.5 使用LangGraph构建大模型的问答流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e9227-785a-4a17-937d-5d27edf9efec",
   "metadata": {},
   "source": [
    "首先，`LangGraph`对目前主流的在线或者开源模型均支持接入，所以大家可以在该框架下非常便捷的应用到自己偏爱的大模型来进行问答流程的构建。这下面的示例中，我们选择比较方便且高效的`LangChain`框架，同时使用`OpenAI`的`GPT`模型来进行案例实现。而关于`LangChain`支持接入的模型列表及方式，大家可以在`LangChain Docs`中查阅：https://python.langchain.com/docs/integrations/chat/ 或者 https://python.langchain.com/docs/integrations/llms/ 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99774090-07df-4d2d-87e4-f5ba2f2893a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个更全面的字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38c51766-fb79-43d1-9b08-a507c4a35bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv('../config/.env')\n",
    "\n",
    "# 获取模型 API 密钥\n",
    "model_api_key = os.getenv(\"QWEN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "591acfd6-f1a5-4e28-9a34-b7134b489784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def llm_node(state: InputState):\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"你是一位乐于助人的智能小助理\"},\n",
    "        {\"role\":\"user\", \"content\":state[\"question\"]}\n",
    "    ]\n",
    "    llm = OpenAI(\n",
    "        api_key=model_api_key,\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "    )\n",
    "\n",
    "    completion = llm.chat.completions.create(\n",
    "        model=\"qwen-turbo-2025-04-28\",\n",
    "        messages=messages,\n",
    "        extra_body={\n",
    "            \"enable_search\": False,\n",
    "            \"enable_thinking\": False\n",
    "        }\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5dd7b3a-5662-4f7d-b5d7-5e0493576095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明确指定它的输入和输出数据的结构或模式\n",
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"llm_node\", llm_node)\n",
    "\n",
    "# 添加便\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7cbbe8fd-42e0-4f45-830e-488875c58c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '你好呀！很高兴认识你～我是你的智能小助理，有什么问题或者需要帮忙的地方都可以告诉我哦。你刚才说是在测试，是想看看我的功能吗？我可以帮你解答问题、提供信息，或者陪你聊天。你想试试看什么呢？😊'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"question\":\"你好，我用来测试\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d2aab-dc9d-42c8-9859-67e4a4f9dc78",
   "metadata": {},
   "source": [
    "更进一步地，如果想在原有的图结构中构建更复杂的功能，则只需要新定义一个`Python`函数，并按照自己的预期流程用边来建立连接，如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67e892f7-1938-4f25-ae0d-497ef901e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict, Optional\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 定义输入的模式\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "    llm_answer: Optional[str]  # 表示 answer 可以是 str 类型，也可以是 None，想要记录state，这里需要有数据类型\n",
    "\n",
    "# 定义输出的模式\n",
    "class OutputState(TypedDict):\n",
    "    answer: str\n",
    "\n",
    "# 将 InputState 和 OutputState 这两个 TypedDict 类型合并成一个更全面的字典类型。\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d48763a8-8b1b-42fc-a830-3a2cf8673546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_node(state: InputState):\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"你是一位乐于助人的智能小助理\"},\n",
    "        {\"role\":\"user\", \"content\":state[\"question\"]}\n",
    "    ]\n",
    "    llm = OpenAI(\n",
    "        api_key=model_api_key,\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "    )\n",
    "\n",
    "    completion = llm.chat.completions.create(\n",
    "        model=\"qwen-turbo-2025-04-28\",\n",
    "        messages=messages,\n",
    "        extra_body={\n",
    "            \"enable_search\": False,\n",
    "            \"enable_thinking\": False\n",
    "        }\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return {\"llm_answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3dcde651-124e-44a9-a412-8fd3698f7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_node(state: InputState):\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"无论你接收到什么语言的文本，请翻译成法语\"},\n",
    "        {\"role\":\"user\", \"content\":state[\"llm_answer\"]}\n",
    "    ]\n",
    "    \n",
    "    llm = OpenAI(\n",
    "        api_key=model_api_key,\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "    )\n",
    "    completion = llm.chat.completions.create(\n",
    "        model=\"qwen-turbo-2025-04-28\",\n",
    "        messages=messages,\n",
    "        extra_body={\n",
    "            \"enable_search\": False,\n",
    "            \"enable_thinking\": False\n",
    "        }\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56e72116-901a-41a5-a1d0-ade1dec2a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"llm_node\", llm_node)\n",
    "builder.add_node(\"action_node\", action_node)\n",
    "\n",
    "# 添加便\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "builder.add_edge(\"llm_node\", \"action_node\")\n",
    "builder.add_edge(\"action_node\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b28ebbda-39ce-4224-9dd2-f7938d4ee37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour ! C'est un plaisir de discuter avec vous. Je suis un assistant intelligent qui aime aider les autres. Mon nom est Tongyi Qianwen. Bien que je n'aie pas d'apparence physique réelle, je peux communiquer avec vous par le texte, vous aider à répondre à des questions, créer des textes, exprimer des opinions, etc.\\n\\nJe peux faire beaucoup de choses ! Par exemple :\\n\\n- Vous aider à écrire des histoires, des documents officiels, des e-mails, des scénarios, etc.\\n- Vous raconter des blagues, des histoires, des connaissances\\n- Faire des exercices mathématiques ou apprendre des mots ensemble\\n- Discuter avec vous et vous tenir compagnie\\n\\nBien que je ne puisse pas ressentir des émotions comme les humains, je fais de mon mieux pour comprendre vos sentiments et vous répondre avec des paroles chaleureuses. Si vous avez besoin d'aide ou si vous voulez simplement parler à un ami, je serai très heureux de vous servir.\\n\\nAu fait, j'ai une capacité spéciale : je peux me souvenir du contenu de nos discussions précédentes, ce qui permettra de mieux vous comprendre et de vous aider. Cependant, je ne conserverai aucune information privée, vous pouvez donc être tranquille en parlant avec moi.\\n\\nAlors, de quoi voulez-vous parler ? J'ai hâte de découvrir plus de sujets intéressants avec vous ! 😊\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_answer = graph.invoke({\"question\":\"你好，请你详细的介绍一下你自己\"})\n",
    "final_answer[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339719dd-a841-4b05-9dc2-f18f90613b86",
   "metadata": {},
   "source": [
    "当深入理解了`LangGraph`的底层原理及其图结构构建的逻辑后，我们是可以明显感受到其相较于`LangChain`中的`AI Agent`架构，展现出了更高的灵活性和扩展性。在`LangGraph`中，我们可以在各个`Python`函数中定义节点的核心逻辑，并通过边来确定输入与输出模式。此外，节点函数在定义时还可以自主构建中间状态的信息。尽管在本示例中我们使用`LangChain`来接入大模型，但通过节点函数的定义逻辑来看，我们当然也可以完全不依赖`LangChain`，而采用原生方法进行接入。\n",
    "\n",
    "由此可见，正如课程开始阶段所提到的，**虽然`LangGraph`是基于`LangChain`的表达式语言构建的，但它完全可以脱离`LangChain`而独立运行**。总体来看，今天的示例并不复杂，但涉及的知识点和细节颇多。强烈建议大家亲自尝试和体验一下，打好扎实的基础，才能更好的开展接下来复杂循环图的学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d494bbc-b65c-4040-a6b5-16b3be740199",
   "metadata": {},
   "source": [
    "# 2. LangGraph的State状态模式与LangSmith基础使用入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af326c9e-71e0-4857-b694-0ab6a054a2b7",
   "metadata": {},
   "source": [
    "**在`AI Agent`应用程序的设计中，场景的复杂性直接决定了构建图的复杂度**。例如，最简单的场景可能仅涉及一个大模型的问答流程，形式为：START -> Node -> END（其中大模型的交互逻辑被封装在Node中）。而更复杂的场景则可能涉及多个`AI Agent`的协同工作，包括多个分支和循环的构成。无论是简单还是复杂的图，`LangGraph`的价值永远不在于如何去定义节点，如何去定义边，而是在于**如何有效管理各个节点的输入和输出，以保持图的持续运行状态**。`LangGraph`的**底层图算法采用消息传递机制来定义和执行这些图中的交互流程，其中状态（State）组件扮演着关键的载体角色，负责在图的各个节点之间传递信息**。这也就意味着，**`LangGraph`框架的核心在于`State`的有效使用和掌握。在复杂的应用中，`State`组件需要存储和管理的信息量会显著增加。核心功能如工具使用、记忆能力和人机交互等，都依赖`State`来实现和维护**。所以，接下来我们对`LangGragh`框架的探索，都将紧密围绕`State`的实现和应用机制展开，这包括`LangGraph`内置封装好的工具/方法的使用，以及我们自定义构建功能时的实现方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948431d-376d-45a9-9d52-4ee403f45c7b",
   "metadata": {},
   "source": [
    "在本节课中，我们将详细探讨消息（Messages）是如何通过`State`进行传递的，其中包含了什么传递模式和内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3db25a-748d-480f-aa82-2edba2ffb418",
   "metadata": {},
   "source": [
    "## 2.1 LangGraph中State的定义模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a6f24-6ce5-4f1f-acfb-dcbc08c4c5e2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/20241022009.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bbc609-ba50-4ebc-9124-acddfe66afda",
   "metadata": {},
   "source": [
    "`LangGraph`构建的**图中的每个节点都具备访问、读取和写入状态的权限。当某一个节点去修改状态时，它会将此信息广播到图中的所有其他节点。这种广播机制允许其他节点响应状态的变化并相应地调整其行为**。如上图所示，从初始状态（Initial State）开始，其中包含了一条消息 { \"x\": \"10\" }，随着消息在节点间通过边传递，每个节点根据其逻辑对状态进行更新。Node 1 和 Node 2 分别对状态进行了处理和变更，结果是在图的末端，我们得到了一个包含三条消息的最终状态 { \"x\": \"10\" }, { \"x\": \"11\" }, { \"y\": \"9\" }。**从开发的角度来看，`State`实际上是一个共享的数据结构。如上图所示，状态表现为一个简单的字典。通过对这个字典进行读写操作，可以实现自左而右的数据流动，从而构建一个可运行的图结构**。我们可以利用这个流程来复现并理解图中的动态数据交换，整体的设计如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88decb-a565-435f-bc8f-df64f0254fd7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/20241022005.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7e299-35c0-401e-9f0b-bbf401969361",
   "metadata": {},
   "source": [
    "### 2.1.1 使用字典类型定义状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e231ac0c-3cf0-40be-bf3f-99d9286f0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 构建图\n",
    "builder = StateGraph(dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8029774-80c6-42cf-9b13-b28c048dedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(state):\n",
    "    print(state)\n",
    "    return {\"x\": state[\"x\"] + 1}\n",
    "\n",
    "def subtraction(state):\n",
    "    print(state)\n",
    "    return {\"y\": state[\"x\"] - 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed71bb8-8c4a-411e-82bb-8fbb67e634df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x13b77d28050>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "\n",
    "# 向图中添加两个节点\n",
    "builder.add_node(\"addition\", addition)\n",
    "builder.add_node(\"subtraction\", subtraction)\n",
    "\n",
    "# 构建节点之间的边\n",
    "builder.add_edge(START, \"addition\")\n",
    "builder.add_edge(\"addition\", \"subtraction\")\n",
    "builder.add_edge(\"subtraction\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7e7abe7-c940-4759-a49c-f00f8edfeb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('__start__', 'addition'),\n",
       " ('addition', 'subtraction'),\n",
       " ('subtraction', '__end__')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2704866e-1335-4b53-9dd7-5f4b4007e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'addition': StateNodeSpec(runnable=addition(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'dict'>, retry_policy=None, cache_policy=None, ends=(), defer=False),\n",
       " 'subtraction': StateNodeSpec(runnable=subtraction(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'dict'>, retry_policy=None, cache_policy=None, ends=(), defer=False)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19baea91-9440-403c-b8e4-f1beb1b828d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ee9da-a9c4-45c3-972d-6973e8643093",
   "metadata": {},
   "source": [
    "`LangGraph`提供的三种图形可视化方法如下：\n",
    "\n",
    "- **Mermaid.Ink**：一个开源服务，可以根据 Mermaid 代码生成图表的 URL。它通过 API 提供多种输出格式，包括 PNG、JPEG、SVG 和 PDF，并可以自定义尺寸、主题和背景颜色等选项。开源仓库👉：[mermaid](https://github.com/mermaid-js/mermaid)\n",
    "- **Mermaid + Pyppeteer**：使用 Mermaid 结合 Pyppeteer 的主要区别在于如何将 Mermaid 图表转换成图像或其他格式。Mermaid 本身是一个轻量级的工具，用于通过文本描述生成图表的图形表示。而 Pyppeteer 是一个 Python 库，它提供了一个接口来控制 Chrome，自动打开包含 Mermaid 图表的网页，然后通过浏览器自动截图功能捕获这些图表，生成图像文件。\n",
    "- **Graphviz**：Graphviz 是一个图形可视化软件，主要用于自动图形布局。它非常适合于复杂图形的生成，如有向图和无向图，而且它支持多种格式的图像输出，如 PNG、SVG、PDF 等，有更精细的布局控制。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f68851-0746-4f26-a256-cedc45fd4d2d",
   "metadata": {},
   "source": [
    "https://langchain-ai.github.io/langgraph/how-tos/visualization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e9bd1-a143-4299-b9e7-f63634dc09c6",
   "metadata": {},
   "source": [
    "如果是`Linux`操作系统，建议使用`Graphviz`工具。而`Windows`系统建议使用`Mermaid + Pyppeteer`方法，因为在`Windwos`中`Graphviz`并不能直接通过 `pip install`的形式安装，编译安装的方法较为复杂。这里我们就使用`Mermaid + Pyppeteer`来进行图的可视化操作。首先，在当前的虚拟环境中安装依赖包，执行如下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a051c29-a5bb-4ff5-8bd5-6e5cb15f2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyppeteer ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e51e34d-1f85-4371-822a-34e11bf45e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37d1af-5449-4c2f-a27d-6ee93e236715",
   "metadata": {},
   "source": [
    "当通过 `builder.compile()` 方法编译图后，编译后的 `graph` 对象提供了 `invoke` 方法，该方法用于启动图的执行。我们可以通过 `invoke` 方法传递一个初始状态（如 `initial_state = {\"x\": 10}`），这个状态将作为图执行的起始输入。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c5f294e-dbad-40a0-ac83-2ddaa017c2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10}\n",
      "{'x': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y': 9}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个初始化的状态\n",
    "initial_state = {\"x\": 10}\n",
    "\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95d2d5-741e-445e-9a18-92ee06c07e8e",
   "metadata": {},
   "source": [
    "在图的执行过程中，每个节点的函数会被调用，并且接收到前一个节点返回的状态作为输入。每个函数处理完状态后，会输出一个新的状态，传递给下一个节点。这里需要注意的一个关键信息是：**节点函数不需要返回整个状态，而是仅返回它们更新的部分**。也就是说：在每个节点的函数内部逻辑中，需要使用和更新哪些`State`中的参数中，只需要在`return`的时候指定即可，不必担心未在当前节点处理的State中的其他值会丢失，因为LangGraph的内部机制已经自动处理了状态的合并和维护。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5ca01e-30fa-4c38-85e3-c60ad54371ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10}\n",
      "{'addition': {'x': 11}}\n",
      "{'x': 11}\n",
      "{'subtraction': {'y': 9}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"x\": 10}):\n",
    "    print(step)  # 每个 step 都是 {节点名: state更新}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5adbff-26bd-4c19-b089-07b0fc79dbb8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/202410220010.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009cc565-6394-42f8-bf07-fec755ce63c8",
   "metadata": {},
   "source": [
    "总体来看，该图设置了一个简单的工作流程。其中值首先在第一个节点通过加法函数增加，然后在第二个节点通过减法函数减少。这一流程展示了节点如何通过图中的共享状态进行交互。需要注意的是，**状态在任何给定时间只包含来自一个节点的更新信息。这意味着当节点处理状态时，它只能访问与其特定操作直接相关的数据，从而确保每个节点的逻辑是隔离和集中的**。使用字典作为状态模式非常简单，**由于缺乏预定义的模式，节点可以在没有严格类型约束的情况下自由地读取和写入状态，这样的灵活性有利于动态数据处理**。然而，这也要求开发者在整个图的执行过程中保持对键和值的一致性管理。因为如果在任何节点中尝试访问State中不存在的键，会直接中断整个图的运行状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba1fd9-0063-40bc-9382-e58f688b3200",
   "metadata": {},
   "source": [
    "到此为止，我们可以来思考一个问题：既然所有节点都会向状态（State）发出更新，为什么仅通过返回需要更新的键值，就能实现状态的全局共享呢？除此之外，如果我们需要对状态进行更复杂的操作，如新增、删除或修改等，应该如何构造这些操作呢？这就引出了我们需要深入理解的概念——在 `LangGraph` 中如何利用 `Reducer` 函数来精细控制状态的变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e717bd5d-dd9e-48d1-8ddb-7183573567c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10}\n",
      "{'x': 11}\n",
      "all steps: [{'addition': {'x': 11}}, {'subtraction': {'y': 9}}]\n"
     ]
    }
   ],
   "source": [
    "steps = list(graph.stream({\"x\": 10}))\n",
    "print(\"all steps:\", steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576874f8-94cd-4d08-8c45-f42b342be936",
   "metadata": {},
   "source": [
    "可见对于x的打印都是过程输出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5712c58-76e0-40a2-bfa3-8d72b9f9aaac",
   "metadata": {},
   "source": [
    "### 2.1.2 Reducer函数的机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68390b74-0877-40b4-9b65-ec7b247305d1",
   "metadata": {},
   "source": [
    "`LangGraph`内部**原理是：`State`中的每个`key`都有自己独立的`Reducer`函数，通过指定的`reducer`函数应用状态值的更新。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434dc73-7711-420d-95f5-5e781322aec5",
   "metadata": {},
   "source": [
    "`Reducer` 函数用来根据当前的状态（state）和一个操作（action）来计算并返回新的状态。它是一种设计模式，用于将业务逻辑与状态变更解耦，使得状态的变更预测性更强并且容易追踪。这样的函数通常接收两个参数：当前的状态（state）和一个描述应用了什么操作的对象（action）， 根据 `action` 类型来决定如何修改状态。比如，在一个购物车应用中，可能会有添加商品、删除商品、修改商品数量等操作。返回一个新的状态对象，而不是修改原始状态对象。**简单理解，`Reducer`函数做的就是根据给定的输入（当前状态和操作）生成新的状态。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45785757-fd27-431a-88e3-141da2838b83",
   "metadata": {},
   "source": [
    ">  LangGraph Update State 源码：https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.update_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53992c-d1e2-42d8-a08a-a4e41c606a39",
   "metadata": {},
   "source": [
    "`LangGraph`中，如果没有显示的指定，则对该键的所有更新都执行的是覆盖操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc69e8ca-e589-43bc-8e42-78efd370330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10}\n",
      "{'x': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 11, 'y': 9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "\n",
    "def addition(state):\n",
    "    print(state)\n",
    "    return {\"x\": state[\"x\"] + 1}\n",
    "\n",
    "def subtraction(state):\n",
    "    print(state)\n",
    "    return {\"y\": state[\"x\"] - 2}\n",
    "\n",
    "class State(TypedDict):\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "\n",
    "# 构建图\n",
    "builder = StateGraph(State) \n",
    "\n",
    "# 向图中添加两个节点\n",
    "builder.add_node(\"addition\", addition)\n",
    "builder.add_node(\"subtraction\", subtraction)\n",
    "\n",
    "# 构建节点之间的边\n",
    "builder.add_edge(START, \"addition\")\n",
    "builder.add_edge(\"addition\", \"subtraction\")\n",
    "builder.add_edge(\"subtraction\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 定义一个初始化的状态\n",
    "initial_state = {\"x\": 10}\n",
    "\n",
    "graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e207ae7e-07fa-4725-bfae-ce5b888cdd90",
   "metadata": {},
   "source": [
    "我们通过使用 `TypedDict` 来定义 `State` 的模式，从而精确控制图结构中状态信息的格式和类型。与上面所使用的传统字典类型相比，`TypedDict` 允许我们明确指定每个键的类型，有助于防止在状态管理过程中出现类型错误。我们强烈建议在开发过程中采用这种方式来定义和管理状态，特别是在涉及复杂状态逻辑和多个状态依赖的应用中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7812848e-94f8-42d7-befc-40c07dfa7df5",
   "metadata": {},
   "source": [
    "接下来 我们再看另一种情况：在下面的图中，State还是一个结构化字典，其中包含一个名为 messages 的键，该键保存一个字符串列表。我们用这个状态管理节点在执行期间将处理的数据。状态的模式是使用TypedDict定义，它指定消息是带注释的字符串列表。该注释包括operator.add，表示可以通过使用添加操作将新消息与现有消息组合来更新列表。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f28a170f-fdcb-4561-a56f-831ab960489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[str], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96618804-3eba-41a0-97c5-84befb86f2fe",
   "metadata": {},
   "source": [
    "Annotated 是 Python 的一个类型提示工具，属于 typing 模块。它被用来添加额外的信息或元数据到类型提示上。这些信息可以是关于如何使用该类型的指示，或者提供给静态类型检查器、框架和库的其他元数据。这里的 Annotated（typing.Annotated）相当于给类型额外打上 元数据标签。\n",
    "LangGraph 读取这个标注，把它理解为：当多个节点同时更新 messages 时，合并方式用 operator.add。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d0050-e9c8-41d4-aaf0-1e544afeeb5a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/20241022006.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "557e72a3-2530-46da-bc96-1ee064afcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(state):\n",
    "    print(state)\n",
    "    msg = state['messages'][-1]\n",
    "    response = {\"x\": msg[\"x\"] + 1}\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def subtraction(state):\n",
    "    print(state)\n",
    "    msg = state['messages'][-1]\n",
    "    response = {\"x\": msg[\"x\"] - 2}\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 构建图\n",
    "builder = StateGraph(State) \n",
    "\n",
    "# 向图中添加两个节点\n",
    "builder.add_node(\"node1\", addition)\n",
    "builder.add_node(\"node2\", subtraction)\n",
    "\n",
    "# 构建节点之间的边\n",
    "builder.add_edge(START, \"node1\")\n",
    "builder.add_edge(\"node1\", \"node2\")\n",
    "builder.add_edge(\"node2\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d7066cc-65d8-4d98-9f0b-481205bcde0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'x': 10}]}\n",
      "{'messages': [{'x': 10}, {'x': 11}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'x': 10}, {'x': 11}, {'x': 9}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_state = {'messages': [{\"x\": 10}]}\n",
    "\n",
    "graph.invoke(input_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b41ac-11f1-489d-9a6e-85b751de8526",
   "metadata": {},
   "source": [
    "### 2.1.3 在图状态重处理消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca0dce-0fdf-4850-9853-1446647f75e1",
   "metadata": {},
   "source": [
    "`Reducer`机制的一个现实意义是：我们可以基于这种方式去构建历史对话记录。因为目前大多数大模型应用都是接受消息列表作为输入。 就像`LangChain`中的`Chat Model`，需要接收`Message`对象列表作为输入。这些消息有多种形式，例如HumanMessage （用户输入）或AIMessage （ 大模型响应）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76490920-6de2-4b4d-866d-3821aec8eee5",
   "metadata": {},
   "source": [
    "下面这个示例，我们进一步将大模型接入到 `LangGraph` 工作流程中，并允许动态消息处理以及与模型的交互。其余组件与先前定义的图中的组件相同。在这里，第一个节点调用大模型并生成一个输出，该输出是一个`AIMessage`对象类型，然后，第二个节点直接将前一个节点的 `AIMessage` 提取为具体的`JSON`格式，完整代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b221b04d-d566-48c8-a216-8c0929b90fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv('../config/.env')\n",
    "\n",
    "# 获取模型 API 密钥\n",
    "model_api_key = os.getenv(\"QWEN_API_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    api_key=model_api_key,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b09056b-0464-4d99-9913-bd063bc200d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, List\n",
    "from langgraph.graph import StateGraph,  END\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 定义图的状态模式\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[dict], operator.add]\n",
    "\n",
    "# 创建图的实例\n",
    "builder = StateGraph(State)\n",
    "\n",
    "def chat_with_model(state):\n",
    "    print(state)\n",
    "    print(\"-----------------\")\n",
    "    messages = state['messages']\n",
    "    completion = llm.chat.completions.create(\n",
    "        model=\"qwen-turbo-2025-04-28\",\n",
    "        messages=messages,\n",
    "        extra_body={\n",
    "            \"enable_search\": False,\n",
    "            \"enable_thinking\": False\n",
    "        }\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return {\"messages\": [{'role': \"assistant\", 'content': response}]}\n",
    "\n",
    "def convert_messages(state):\n",
    "    # \"您是一位数据提取专家，负责从文本中检索关键信息。请为所提供的文本提取相关信息，并以 JSON 格式输出。概述所提取的关键数据点。\"\n",
    "    EXTRACTION_PROMPT = \"\"\"\n",
    "    You are a data extraction specialist tasked with retrieving key information from a text.\n",
    "    Extract such information for the provided text and output it in JSON format. Outline the key data points extracted.\n",
    "    \"\"\"\n",
    "    print(state)\n",
    "    print(\"-----------------\")\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":EXTRACTION_PROMPT},\n",
    "        {\"role\":\"user\", \"content\":state['messages'][-1]['content']}\n",
    "    ]\n",
    "    completion = llm.chat.completions.create(\n",
    "        model=\"qwen-turbo-2025-04-28\",\n",
    "        messages=messages,\n",
    "        extra_body={\n",
    "            \"enable_search\": False,\n",
    "            \"enable_thinking\": False\n",
    "        }\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return {\"messages\": [{'role': \"assistant\", 'content': response}]}\n",
    "\n",
    "# 添加节点\n",
    "builder.add_node(\"chat_with_model\", chat_with_model)\n",
    "builder.add_node(\"convert_messages\", convert_messages)\n",
    "\n",
    "# 设置启动点\n",
    "builder.set_entry_point(\"chat_with_model\")\n",
    "\n",
    "# 添加边\n",
    "builder.add_edge(\"chat_with_model\", \"convert_messages\")\n",
    "builder.add_edge(\"convert_messages\", END)\n",
    "\n",
    "# 编译图\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a873076d-653c-4163-97a8-7481a022354f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAFNCAIAAAAmRdIAAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/B3ckmABMLeQ6YyZAkCjhZFq21dFWwrqHWUVltH/VbqaOuubVVste5WW0fdiAtHrasOsIhsUAqyBBmGFbLX/f44f2jbfFAsMQd+ng8fPpKb74RXPve5y12OQZIkYJg2TH0XgNEXDgeGhMOBIeFwYEg4HBgSDgeGxNJ3AR3TVK9sbVRKWtVioUql6AI74QwGEGwGj8/imhB8S7aZNVvfFXUAo0sc56irkN3LFZcViMxtOColyeUTXBMWm8PQd11Px2CAQk5KWlUSoZpgM5rrFe7+xu7+xrYuBvou7enoHo7GWkVqisDImGVuw3brbWxu05U+ef/WVKcozRc31ytlEnX/UVY0fzm0Dkfa6cbSfNGAkZaufjx919LJyvLFqSkCjwCTiDct9F0LEn3DcWjd/ZCh5p6BxvouRIeKs0RZV5re+Z+zvgvRjo57KyQJWxJKot616d7JAACvYONBMTZb598DWn5C6dhybJ5XMuNbT4LWm+POpJBqdiwp/Xitp74L+SfaheNgYuXQWFsrxy7Qme9E9fflV5Lq6bZ9oVc4bpxqsOth6BHQ3bqfz6IkW/ywWtZvhKW+C3mMRn0OQbX8fpH45UwGAHgG8coKxA01Cn0X8hiNwnEjpaH/KCt9V6FPA0ZZpaYI9F3FY3QJR02ZjG/OcunF1Xch+tTDh8s1YdWWy/RdyCN0CUdJjsjCjvOCVzp06NDq6uqOznXo0KGlS5fqpiKwsOOU5Ip0tPCOoks4yvJFbi/2MGhVVVVzc/NzzFhQUKCDch5x8+OVF4h1t/wOocW3so21CisHA76lTo5skCS5f//+06dPV1ZWurm5hYeHf/TRR7du3Zo1axYAjBkzJioqas2aNffu3UtKSkpPT6+trXVzc4uJiRk7diwAFBUVTZgwYf369StXrrS2tjYwMMjJyQGA06dPHzx40NOzkw9OmFmzzaw5TXVKc1saHOchaeBenihl5wMdLXz//v1Dhw5NSUkRCARJSUlRUVG7d+8mSfLatWshISFVVVXUZNOnTx87dmx6evqtW7cOHz4cEhKSlpZGkmRpaWlISMj48eN//fXXgoICkiQnT568ZMkSHVVLkuTJH6vLCsS6W/6zo0XLIRGqeHxdVZKZmenn5zdixAgAiImJCQsLk8m09PhWr14tkUjs7e0BIDQ09Pjx46mpqREREQRBAEBkZOSECRN0VOE/8PgssVD1YtbVPlqEQ9yi5vEJHS08MDBw48aNK1as6NOnT2RkpLOz9qOQGo1m3759qamplZWV1BA3N7e2sT4+Pjoq7994pjgcT2AwgMnS1Zk7sbGxXC736tWry5YtY7FYw4cPnz17tpXV3w6oqNXq2bNnkyQ5Z86cvn378ni8KVOmPDmBgcGLO5zPJBhAj8PWtAiHkTHRWKerI4MEQURHR0dHR9+7dy89PX379u1isTgxMfHJaQoLC+/evbt169a+fftSQ1pbW3VUz1OJmpXW9PhqiRa7slydbWVJkkxJSSktLQUADw+P2NjY8ePHFxUV/WMyap/W2tqaelpSUlJRUaGLep6FRKjWXQ+sQ2gRDr4lm8XSSSUMBiMlJWX+/PnXrl0TCoXXr1+/cuVKYGAgALi6ugLAhQsXCgoKPDw8GAzGvn37RCJRWVlZYmJiWFhYTU2N1mU6OzsXFhZmZGQ0NTXpomYWm8G3fNHHA7XT9+7SIz8vKxU1K3Wx5Jqamnnz5oWEhISEhAwfPnzbtm0ikYgatWzZMuqwB0mS586dGzduXEhIyNixY/Pz83///feQkJDY2NiKioq23VpKZmZmTExM3759b9261enVChuVu1aUdfpinw9dvrK/kvTQyoHTu7+pvgvRs9zrLU31ishoa30XAnTZrACAu79xQy2Nvq3Wl8ZahYc/XU6OpEXHBwBcehml/9ZQUy6zdzXUOkFVVdXEiRO1jiIIQq1Wax01btw46jC5LiQkJGRkZGgdZWFh0djYqHXU8uXLIyMjtY56cE/aWCt3GkeLZoNeZ4I9KJWlnRHEzHLSOlalUtXX12sd1draamJionUUj8czNdXVpkogECgU2ls7mUxmaKg95RYWFqhRSRuqBo6xskN8PF48urQcAODgbmhlb1D1l8Spp5azOlgsloODgz7qQvrHkbT/qPKuxMbZkD7JoFGfgxIZY/37gXpRMy0OHr9IwkbV5SP1r0bT60Q4eoUDAOLmu+xfU6nvKl60A2sq4ub30HcV/0SjPkcbtZLcuaxswvwePFNdfRtHH6Jm1b7VFfEr3Qmdfbv03OgYDgCQSTQH1lQMm2jv6EmjbXCnu/+X9OLBurj5LhxD2jXh9A0H5UrSw+Z6Rf9RVjbOtPgiqhPVVcpTTwnMbTmDaLPj+m+0DgcAVBVLU1ME9m5GVg4ct97Ghlw6fsKenUysKSsQCR4oasqlA0ZaOXoa6bui9tA9HJTyQklJTmtZgdjVlwck8PgsLp/gGHSNoCjkGrFQJRGqAaDijtitt7FHoLGrTxe4CKNrhKNNbbmspUEpblGJhWqlXNO5Cy8uLmYymR4eHp24TAaTweYwuHyCx2eZWnLsXLvS9pFGB8GehZ2rDg8T/bUtmcFiRb3bT0fL73K6RsuM6QUOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XA8xmQyWawudiGPTuFwPKbRaFSql+53Y9qBw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGFIX+wVjXRg8eLBQKNRoNAwGg8FgUHfNNDMzu3z5sr5L0zPcckB4eDhJkgRBMJlMBoNB/T9w4EB916V/OBwwefLkf9w9zs7OLi4uTn8V0QUOB/j4+AQEBDw5JCQkxMfHR38V0QUOBwDAxIkT7e3tqcd2dnYTJkzQd0W0gMMBAODr69vWeAQFBXl7e+u7IlrA4XgkLi7O1tbWzs5u0qRJ+q6FLp7zMg1BtbyhViEWqklNt9kTdgj1fIckSVGVze2qJn0X0zmYBINrQljaGVg5cp5j9uc5znF2V61UrDHkEcam7G4Ujm6IQTBEzUq5WG1kzHx9sl2HZ+9oOI5tfuAZzHf1M+7omjA9Ks0TlecLx8zo2P3eOxaOc3tqHdx5bv4mHS8P07N7Oa31lZJhE22ffZYOdEibHypbBCqcjC7KI9CkoVYhbOjA9Z4dCEdDjZzL7/73D+/GeHyWoEb+7NN3IBwSoZpnwn6uqjBa4PJZEqFuWg4SSM1L/xVul0ZqoEN/QHwQDEPC4cCQcDgwJBwODAmHA0PC4cCQcDgwJBwODAmHA0PC4cCQcDgwJP2E4+1339ixc7NeVg0AfxXfHTwktKAg9x/Dq6oqBw8JvZVxU091PdLQIBg8JPTqtUvtT3Y0+eDQYeE6raQrtRzLli84c/bEf1+OpYXVe5PiraxsAKC0tGR83MhOKK476krhuFtU0CnLsbS0mjplhq2tHQDcuZvfKcvslnR7kwC1Wn3o8N49e39iMBh+vgFTp8zw83t0eQiLxU5OPrh1+3oDAwN//+BFC1fwTfgAUFZ27+SppNuZ6fX1tT1c3EaNihk5YqxKpXpteAQArE1cuf3HH04cu4ha46pvFrc0N61ZvYl6OmHSW3K5LOnwOerp8hULFUrF5Pc+nD5j4qYffk67eW3f/l8AYPCQ0FkzE8LD+lM1r1m74uy5k5aWVpGRQ2fPTGj/NR49emD/wV3ffL1h8ZJ5jY0NLi6u8z79srFRsHrNMrVaHR42YO7cRaZ8UwCQSCTfrf86OzujtVXo2sP9zTffGjN6HLWQi5d+++WXrSKxqF/EK+Ni/nYlZl5e9u49PxYVFVpYWkWED5wyebqRkdF/+7M8K922HNt//OHUqaMrV6z7YtFXllbWCxbNrqqqpEZdvnJeKpOuWb0pYd7inJzbu3Zvp4Zv3LQ24/afcz9Z+M3XG954Y8y671bdyrjJYrHOnbkBAJ8lLG4nGQAQ2ie8oDBXo9FQG++mpga5TPagppoam5uXFdLn8XY6/v2Z4999z9bW7vLFjJjo8dTA3Xt+7NMn7Lt128bFxCUnH/zjanurAwA2h9PaKtyz96d1idtOHLskk8m++XbJ+fOnf95xeM+u5NuZ6cnJB6gpF34+p6ametVX3x86cHrAgEHrN3z7V/FdatO26usvhw0buXvX0aFD3/hh05q2hVdWls9fOEupUm7ZvHvp4m+Li+9+mjCDenUvgA5bjpaW5iNJ++Z+srBvaAQAREQMlIjFDQ0CJycXADA2NpkQN5Wa8vr1y3m5WdTjpUtXSyUSOzt7AAgOCj1z5nh6eiq1hGcRHNxXIpGUlpZ4evbMyc309OzFZrHzcrMc7B2rqiobGxtCQ8Jlclk7S+gT3HfokNeptScd3Z+blxX56pB2pmcymUqlcsp7050cnQEgPHzAyZNJGzfsNDMzBwB//6B7pcUAcPPPG3l52bt/SXJxcQWA9ybF/5l+49dfd65YvvbEySO2NnbvTYoHgJA+YY0Ngtz/fzcuXDzLZrFXLFtramoGAPPmfTlx0lupaVcHDhj0jG/If6HDcJSXlwKAj0/vR2tisVauSGwb6987qO0x39RMrnh0biOp0Rw5ui89PbWtjenRw+3ZV2pjY+vs3KOgMNfTs2dubqafbwBBEPkFOcOHj8zJzbSxsXVxcaU+ryhPFmZqaqaQP9NJlx4eXtQDrhHX0tKKSgb19KGgHgDKykq4XC6VDEqvnj6paVcBoLr6vqubR9twb2+/tsf5+Tne3n5UMgDA0cHJztY+Jyezy4dDLBZR7472FT9xTyQGg0E9UKvVCxbOJkly+odzgoP68ni8j2dN6eh6g4NC8/Ozx4wel5uXFT9tJpPJ3Lp9PbVNCQ7q+9TZCW2FPdWTU2qdq6FBYPT3t8LIiCsRiwFAKGx5MjSGho+7FCJRa3FJ0eAhoU/O2NTU8IxV/Uc6DAeXywOAVlHrs89SVFT4V/HddYlb+wQ/+iuKOjI7pU+fsO3bN7S0NJeXlwYFhZIkef9+RUtLc35e9pQpMzq6tM7C4/EkEvGTQyQSsaWVNQDw+abyJ9qnJyezsLTyNzKa+veyTflmL6RkXXZIPTx7EgSRk3ObeqrRaOYvmPX772famaWlpRkArCytqaelpSX371d0dL3BwX1r62ouXvrN3d2Ty+XyeDwvz14XLp57UFP97H2XTterp69UKi0tLWkbUliY5+bqAQC2tvaFd/LauplpN6+1TePh7iV4WB8UGBIcFEr9MzezeLKZ0SkdhsPE2GTYayNOnDhy9tzJrOyMHzauycrO8PH1b2cWVzcPBoNxJGmfSCSqqCjbtDkxpE9YbV0NABgYGFhb22RmpmdlZ7R/Jza+Cb+nl3dy8oEA/2BqiF/vwOTkAz29vNu6Am2cnFwaGgQ3bvzR1sXRkbCw/g72jonffXW3qLCxseGnHZv+Kr5L7bUOGvRaY2PDlq3fkyR5OzP9xIkjbXO9884klVq1acs6mUxWWVm+bfuGafHvVlSU6bTUNrrdlf1kzoKgoNB13636dN6MwsK8lSvWUV16FHs7hy8+/yovP3vUmEFfLpn3wQezR46Mzs/P+eDDOACYEDct4/afi5fMUygU7a83KCi0+kGVn18g9dTPN+BBTXVQUOi/p4wIH+jfO+jLJfMuXT7/317rU7BYrK9WfmdibPLxzMkTJo3Jzrm9auV3vr7+ANA3NGL6h3PS0q5GDe2bmLjy80UrAYC6TNWUb7pzxyFDA8P4D2MnTx2Xk5u54LOlbZ1fXevAtbK515vrq5Thb1jruCRMV26efmjXg+M/wPQZp+9Kh8+xF6xL3mP3reihakS34/NFK/v1e6VzV7d4SUJ2dobWUaNHj/sgflbnro4+umQ4tm7ZgxplbmbR6aub+8lChVJ7L4faXe+uumQ47O069iMk/5GlpdWLXB194D4HhoTDgSHhcGBIOBwYEg4HhoTDgSHhcGBIOBwYEg4HhtSBcBjyCPxL510aqSG5xh34JdkOhMPK3qCuor3ztjGaq62QWjoYPPv0HQiHhR2HZ8Z6WIXz0SXVV8pMLdlm1h34meGO9TlGTLW7/bugqe4pJ2JhdNNYq7h9UfDmNPsOzdXhW2rIJZqjm6qsHY14ZixjM7YG90JojMlkiJqUEqHqYbU0ZrYTx7BjbcFz3nS4JFtUXyWXtGo06hd0ad4LUFNTw2Qwbe06cNMJmmMSDB6fsHYy8Ax8nvvj4DtSP7Zt2zYWixUfH6/vQugCH+fAkHA4MCQcDgwJhwNDwuHAkHA4MCQcDgwJhwNDwuHAkHA4MCQcDgwJhwNDwuHAkHA4MCQcDgwJhwNDwuHAkHA4MCQcDgwJhwNDwuHAkHA4MCQcDgwJh+MxFovFZnfgUtJur0v+SK2OtH+njpcQbjkwJBwODAmHA0PC4cCQcDgwJBwODAmHA0PC4cCQcDgwJBwODAmHA0PC4cCQcDgwJBwODAmHA0PCP1ILUVFRLS0tJEkyGIy2/83MzC5duqTv0vQMtxwQHh6u0WiYTCaDwaD+B4D+/fvruy79w+GAiRMnOjo6PjnEwcEhLi5OfxXRBQ4H+Pn5BQQEPDkkMDDQ19dXfxXRBQ4HAEBsbKy9/aN7kdjb20+YMEHfFdECDgcAgL+/v7+/P/U4ICAANxsUHI5HYmNjra2tcbPxpKdfmtBQq2yolomF3f60facQjxiCIOR19ll1TfouRrd4piwrB0MLu6dcpNPecQ5SA6d2PBC3qM1sDQyNOnDLSYzmpGKVsEHB47NGxtszGMjJkOHQqMnkzdV+/SycenJ1WCamP/eLxIV/NkfPdGQiOhfIcBzbUu3Xz8Le3Ui3BWJ6VV0iKcpoHjPdQetY7ZmpKZMxCSZORrfn6MklNVBbIdc6Vns4BA/kXBN8Ge1LgWvCaqjpSDikrWquKQ7HS4FnypK0KLWO0h4OkgRS/bJ/W/uS0GiABO17LPggGIaEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGFK3DUfysUPfrF6q7yq6tm4bjrtFBfouocvrtJM21Gr1ocN79+z9icFg+PkGTJ0yw8/v0WVke/buOH8+pf5hna2tfUifsDmz5zOZzJKSvz6YHrdl8+59+3++ceMPGxvbwYOGTf9wjkQieSt6yLSpH8WOn0zNrlKpxoyNih47/v1pHwsED7ds/a6gMFcul4eF9Z/83oeODk4AkHR0/8FDe+Z+snDZ8gXRY8ffuZufn58DAOfPn97500F3d09U2YuXJLDZ7PCwAeu+X8Visbx7+S1dujo5+cCevTvMzS3eeH30B/GzqCnz8rJ37/mxqKjQwtIqInzglMnTjYyMAIAkyaSj+8+fP11VXdnDxS0kJHza1I8IgkANp1q1mzev3bmTzzEwCA4Kff/9mfZ2DtR7+MPGNddvXOGwOcOGjfDy9F68NOF48gVTUzMAOHP2xKmU5PLye+7uXlGDh8dEj6cKKy8v3bV7e1Z2BkEQfr4B774zqXfvwE75m3Zay7H9xx9OnTq6csW6LxZ9ZWllvWDR7KqqSgD4Zde24ycOf/zRp0lHfpsyefrvF84cO3YIADgcDgAkrlv52tA3z59LW7hg+aHDe6/8cYHH44WHD7h2/XLbklPTrkokkuHDR6lUqk8TZuTlZyfMW/zLzsMmJvyPPppUU/sAANhsjlQqOXhoz+eLVo4ePW7jhp0+Pr2HDRtx+WJGO8mgysjNy7pzN//IobObN+7Kzcv6ZG48k0mcPnV1wfxl+w/sysrOAIDKyvL5C2cpVcotm3cvXfxtcfHdTxNmaDQaAEhOPrj/wK63x03Yt/fEm2++lXL62JGkfe0Mz86+vXHTWn//4BUrEhcuWF7/sO7rbxZTxRw6vPf0meOfzFmwffs+gmDt3vMjADCYTAD4/fczaxNXevfyPbDv1NQpMw4f2btl6/cAoFAoPk2YweZwvl+3ffW3GwHgi8WfKpXaT97pqM5pOZqbm44k7Zv7ycK+oREAEBExUCIWNzQITM3MDxzcPfPjef37vwoAQ6KGl5YW7923c+zYd5lMJgAMinwt8tUhABAcFGpra/fXX3cGD3ot8tWhX3+zuKFBYGlpBQBXr1709Ojp5Oh8OzP9/v2KdYlb+wT3BYCZH32alnr16NEDs2bOIwhCIpG8P+3j4KDQDlXOZDLVavXMj+ex2WxTU7MePdyYDObk9z4AgPCw/lwut6SkKDgo9MLFs2wWe8WytdSHeN68LydOeis17erAAYNycjO9vf2GDRsBAKNHxfTpEyaXyQAANdzfP+jnHYdcXFypVkQuly1ekiASiYyNjX87n/LqK1GvvhIFAO9Nis+4fbOtzlOnkwMCgj+ZswAAQkPCJ7/34Xfffz0hbqpA8LCpqTEmOpb6DCxbujo3L0utVnfKjWM6p+UoLSsBAB+f3tRTFou1ckViYGCf+/crlEqlr69/25ReXt4tLc3Uxx0Aevb0aRtlbGwiErUCwCsDBxsYGPzxxwVqm3L9xpWoqOFUw85ms6lkUH/XgMA+eXlZbUvo1fN5LmN0du7R9lZyuTxXN4+2UVwujyopPz/H29uPSgYAODo42dna5+RkAkDv3oG3bqWtWbvit99SWkWtTo7OHh5e7QwnCKK6+v78BbNGjo4cPCR08ZIEAGhublSpVJWV5X5+j7cIrwwcTD1QqVSFhXl9Q/u1jQoO7qtWq/Pysp2cXMzMzL/5dsm+/b8UFOQSBBEcFGpoaPgc78O/dU7LQb2DXKN/XuHS2CgAAEODx7UaGXEBQCqRUC+Aqe2SCUNDw34Rr1y9fik6evyN1D/kcnnU4OHUWpRK5eAhf2sbqNaFQm2qOuofNWgtSSRqLS4p+seqm5oaACAmOtbIiJuadvXbNctYLFZU1PAP42dbWlqhhl+9dmnpsvnvTYqf+fE8d3fPmzevL/piLgCIJWIAoPoxFL6JKfVAJpOp1eqdP2/Z+fOWvxXQ3GhgYLDh+59Onzl+JGnfjp2bHR2dp0yePnTI68/xPvxb54SDxzMGgFZRq9bhUpm0bYhUKgEAKytr0b8mftKgQa8tX7GwpaX52rVLAQHBtrZ2VA6MjIxWffX9314A8SJOhLawtPI3Mpo6ZcaTA035ZlRLMGpk9KiR0WVl9zIz03ft3i4Ri1euSEQNP336WEBAcNuiRGIR9cDI0Ijqk7Ytv6m5kXpgbGxsaGj4+vBRr7465MkCHB2cAcDFxfWjGXOnTpmRkXHz3PlTq77+0senN9VP/48655318vImCCIn57aPtx8AaDSahYvmvDb0zfCIgQRB5Ofn9PTypqa8cyff3NzCzMy8/XD0i3jFyMgoNe3qn+k3PoifTQ10d/eSSqV2dg5U3x4Aqh9UWZhbdspLaJ+Hu9fly+eDAkMY/3/1YHl5qZOTC0mS58+f7tXL19XV3c3Nw83NQ9jacv78adRwABAKWxye+Mtdu/box6U4HI6lpVV5RWnbqBupf7Q9dnf3ksqkbT0qhUJRV1djY2NbUVF2527+68NHGRoaDhw4KCJi4PA3+ldVVXZKODqnz8E34Q97bcSJE0fOnjuZlZ3xw8Y1WdkZPr7+fBP+kCGv7/11R2rq1VZR67nfTp08lTQu5uk/msPhcPr3jzx+/LBUKo38/49LeFj/sLD+a9euqKurbW5uSj52aMaMib+dT9G6BEdH56KiwqzsjObmTrgq+p13JqnUqk1b1slkssrK8m3bN0yLf7eioozBYPx2PmXp8vlpadeErcKbN69fv3HFr3cgajgAeHj0vJ2ZnpOTqVKpDh/5leqW1tXXAkD/fq+eO3cyM+uWRqM5dHivRCJuK2D6B3OuXr145uwJtVqdm5u1fOXCeZ99pFAompubVq9ZvnXb+uoHVeXlpb/u+1mj0bj2cP/vL7kzj3N8MmfB+g3frvtulVqt9vLstXLFOidHZwCYPfOzrcT3K1d9rlKpHB2dJ02Mf/edSc+ywMGRr32x+NOIiIFt3UAA+GbV+pOnjq74alFhYZ6Li+sbb4x5a8zbWmcfNSJ63ferEj77OHHtlo7uwvybKd90545DBw/ujv8wtrr6vre334LPllIdzAXzl23anPj5l/+jNnwjR4x9e9zEdoZ/ED9LKpV8/uVcqVT69rgJC+Yvq6qqTPjs4+XL1kydMqOuvnZewkeOjs4hfcKix45PXPcVh80BgICA4O1bf923/5dt29YrlApfH/+vVn7H4XACA/t8+r/Pd+3efvjIrwDQNzTi+3Xbqa3wf6f9Wtk/zzYqlRAYadEp68CekUwmq6+vdXFxpZ7u2//LkaR9x5Mv6HSl2VcaDQwhbLiWv3W3PXzeFe0/8MuHMyYcP3GkpaX5wsVzSUf3jx4Vo8d6uv81j29FD1Ujbhj7+aKV/fq98sIrQpo6ZUZLS/PZsye2bV9vY2MXEx0bFztFj/V0/3Bs3bIHNcrcjF7bTQaD8b+5i/RdxWPdPxxt+71YR+E+B4aEw4Eh4XBgSDgcGBIOB4aEw4Eh4XBgSDgcGBIOB4akPRyGPOZLf+u3lwYJRsbaf9heezgs7Q3q70u1jsK6mbpKqYWd9nNvtYfDydNIIdGIW7r9bTRedqImlUqhcUT8jjnq9/LhjWl214/XySUa3VaH6Y9MrL5xsu7NafaI36ht934rwgbloe/v9/A1MbfmGHBx17X7kIk0LQ3yijvid/7nzLdAfjP/9JsO30lvFVTLX4I7NUFdXR2DwbCxsdF3ITrH47OsHA18wkzanwzfkfqxbdu2sVis+Ph4fRdCF3hjgSHhcGBIOBwYEg4HhoTDgSHhcGBIOBwYEg4HhoTDgSHhcGBOWNeXAAAHkElEQVRIOBwYEg4HhoTDgSHhcGBIOBwYEg4HhoTDgSHhcGBIOBwYEg4HhoTDgSHhcGBIOBwYUvf/HdJnx2azO+XuV90GDsdjSqUSX+L1JLxZwZBwODAkHA4MCYcDQ8LhwJBwODAkHA4MCYcDQ8LhwJBwODAkHA4MCYcDQ8LhwJBwODAkHA4MCf9ILURFRTU3N1M3hKaGkCRpamp6+fJlfZemZ7jlgPDwcABgMpmM/wcAAwYM0Hdd+ofDAXFxcY6Ojk8OcXBwGD9+vP4qogscDvD39+/du/eTQwICAv4x5OWEwwEAMH78eAcHB+qxvb19XFycviuiBRwOAIDAwMC2pqJ379642aDgcDwSGxtrY2NjY2MzadIkfddCF13z0gQSmh4qxUKVRKhSyUmVulPuNeYc5D4aAFSNDrnXm//74ggWk81h8PgsLp9lbs1G3SqLzrrScQ6VAoqzhcXZ4voqBQCwDQiCQ7AMWBo1HV8CQTCUcpVaoVbK1UCSti4GXkHGnkEmrK5z2VSXCcfNM41lhRIGi8U155pY8xhd6oNIkiCsF0ubJaRK5d6bG/66hb4reiZdIBx/ZYouHKiz9TC17GGu71o6QUN5U31Zy5Dxtj37GOu7lqegeziuHhMI6kgzJ3Mm0aXainZp1GTT/SYbe8Yrb1npu5b20DocZ3bVyRRsC2dTfReiEw2VzTyu+vVJ9L0ZJX3DcWpHrVzFserRPZNBEZS3GHIUI9+303ch2tH0OMcfxwSK7p4MALByNZUp2NeON+i7EO3oGI6i260Pa0jL7p4MipWrWV21pjhTpO9CtKBjOC4feWjubKbvKl4ccyezS0fq9V2FFrQLx5+/NZo7mhAs2hWmOwSHaWZvcuv3Jn0X8k/0+huQJJTkSGw9u8Yxok5k62VRnCUGmu0b0Csc93JFwCT0XQWSsFWQsDg8t0Anpw9qGMzSfLEulvzc6BWO4mwxz4Kr7yr0g2fOLc7G4UATVCv41jx9V6EffFtefbVC31X8DY2+shcL1VKxisnS1WHyFuHDk2fXV9zPUyrl3l79Xhscb2XpBADX0g5eurpnxtTNuw8srBeU29t6vjogrm/wCGqurNzz5y5ul8lEvr0GvtJfhyeWEiympEUhFamNjOmyYaVRyyERqjiGunpf1GrVtl9mllXkvD3mi4TZB4yM+Bu2TWlsegAALIIjkQqTU9a+G7147Yqbfj6RR46vahE+BICaupL9SUtCg9+c/8nhPoGvH09Zp6PyKBxDllio1ukqOoRG4RAL1SwDXYWjtDzroaAidtyyXl7hJsYWo9+Ya2Rkci3tEAAwmEy1Wjl8yIc9nHszGIzQoDc1GnV1zV8AkPrnUTNTu9cGvc/jmnp59A0PHaOj8igsQ0IiVOl0FR1Co3Bo1CTB1tVmrqwimyDYXu6h1FMmk+nuGlxWkd02gYujH/WAa8QHAJlcBACCxvt2tu5t0zg7+uqoPAqLQ9DqxCUa9Tm4JoRCoqsemVQmUquVCYvDnxzIN3n8jTlD2+lDEonQxqpH21MOx0hH5VHkYiXXhEZ/ERqVwuWzlDJdbXFNTCw5HKNpE/7WaSCIp2zFuFy+UiVveyqX63ZXUylTcfl06Y3SKxzGpiyeqa5OsHSw9VIopBbm9hbmj65PETRUmZhYtj+XuZn9naIbGo2GyWQCQGHRdR2VRzE2Yxub0ugvQqM+B5MAtgGIGqS6WLh3z37eXv0OHfuqqblWJG66fvPw+m2TM7JOtz9XoN/QVlHDqXMbSJIsvncrNf2oLmqjtD6UcIyYtDpJnUY5BYCewbyCWxJjS51s2qdN/C7tVvKvh7+suJ9nY+0a1mf0gPBx7c/Syyt8xLBZN28du5Z20NzMPm7css07poNuTo9qFUj8I+h1AJBeZ4K1NqlTfq6z97XVdyF6UFNYOzrejmdKoz4HjTYrAGBiTpjbEE3Vrfou5EVrrGq1tGPTKhm026wAQORYqz2rKswdTbSOVamUy1a/jhilYBFs0LZHam/rOTN+eycWufSb4WoN4mgVSWqtwcm+14xpW1ALrL/XOGKJaydW2CnotVmhpJ5urK9lmjloz4dUqr1dUSrlbLaB1lEMBtPQsDM356gaqOP0BKHlI9dODc3VrQ7OmrDhtDuLhY7hAIADiVWmjuZcM0N9F6Jz4kaZqK7p3U+d9F2IFvTqc7SJTXCqzKlTqzrlCmn6Uis0Vfl19EwGfVsOANCoYefSMudAO0Njjr5r0QlZq6K6oG7qElfanvtG33BQ9n5daeZkbmLd3U4Pa30obnnQPHGhi74LaQ/dwwEAlw4/rL4nt3Sz4Jpq7292LZJmuaCswcnLKOptWl8o2zXCAQAP7kn/OCYgDAwMjA1NrLld8aJqjZoUPpTIRTJSoYgca2Xv3gX62l0jHJSyAkl+mvB+kZhvwyXYBMuARf1+C2jo+BIYDIZKoVbK1SqFSi1XCxskzr14/v34rr5dZhPZlcLRprpYWl8tb21Si1pUDAZDJqHRqXVtDLkEAMkzZZmYETZOBo6euj0XRBe6ZDiwF4OmxzkwOsDhwJBwODAkHA4MCYcDQ8LhwJBwODCk/wM1pyVxMiYHXQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b961d502-db90-44c1-bf6c-0427d14bb3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'user', 'content': '你好，请你介绍一下你自己'}]}\n",
      "-----------------\n",
      "{'messages': [{'role': 'user', 'content': '你好，请你介绍一下你自己'}, {'role': 'assistant', 'content': '你好！我是通义千问，是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我能够回答问题、创作文字、编程、逻辑推理等多种任务，旨在为用户提供全面、准确和有用的信息与帮助。\\n\\n我的训练数据来自大量的文本，包括书籍、文章、网页等，这让我能够理解和生成多种语言的内容。我可以帮助你学习知识、创作内容、解决技术问题，甚至进行简单的对话和娱乐互动。\\n\\n如果你有任何问题或需要帮助，随时告诉我，我会尽力为你提供支持！'}]}\n",
      "-----------------\n",
      "{'messages': [{'role': 'user', 'content': '你好，请你介绍一下你自己'}, {'role': 'assistant', 'content': '你好！我是通义千问，是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我能够回答问题、创作文字、编程、逻辑推理等多种任务，旨在为用户提供全面、准确和有用的信息与帮助。\\n\\n我的训练数据来自大量的文本，包括书籍、文章、网页等，这让我能够理解和生成多种语言的内容。我可以帮助你学习知识、创作内容、解决技术问题，甚至进行简单的对话和娱乐互动。\\n\\n如果你有任何问题或需要帮助，随时告诉我，我会尽力为你提供支持！'}, {'role': 'assistant', 'content': '{\\n  \"key_data_points\": {\\n    \"模型名称\": \"通义千问\",\\n    \"所属机构\": \"阿里巴巴集团旗下的通义实验室\",\\n    \"功能描述\": [\\n      \"回答问题\",\\n      \"创作文字\",\\n      \"编程\",\\n      \"逻辑推理\"\\n    ],\\n    \"训练数据来源\": [\\n      \"书籍\",\\n      \"文章\",\\n      \"网页\"\\n    ],\\n    \"语言能力\": \"多种语言内容的理解与生成\",\\n    \"应用场景\": [\\n      \"学习知识\",\\n      \"创作内容\",\\n      \"解决技术问题\",\\n      \"简单的对话和娱乐互动\"\\n    ],\\n    \"目标\": \"为用户提供全面、准确和有用的信息与帮助\"\\n  }\\n}'}]}\n"
     ]
    }
   ],
   "source": [
    "query=\"你好，请你介绍一下你自己\"\n",
    "input_message = {\"messages\": [{'role':'user', 'content':query}]}\n",
    "\n",
    "result = graph.invoke(input_message)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d440c8aa-60db-47f3-98bb-7ef94cb6dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"key_data_points\": {\n",
      "    \"模型名称\": \"通义千问\",\n",
      "    \"所属机构\": \"阿里巴巴集团旗下的通义实验室\",\n",
      "    \"功能描述\": [\n",
      "      \"回答问题\",\n",
      "      \"创作文字\",\n",
      "      \"编程\",\n",
      "      \"逻辑推理\"\n",
      "    ],\n",
      "    \"训练数据来源\": [\n",
      "      \"书籍\",\n",
      "      \"文章\",\n",
      "      \"网页\"\n",
      "    ],\n",
      "    \"语言能力\": \"多种语言内容的理解与生成\",\n",
      "    \"应用场景\": [\n",
      "      \"学习知识\",\n",
      "      \"创作内容\",\n",
      "      \"解决技术问题\",\n",
      "      \"简单的对话和娱乐互动\"\n",
      "    ],\n",
      "    \"目标\": \"为用户提供全面、准确和有用的信息与帮助\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a650c-9521-4ce4-87b0-1667198db62f",
   "metadata": {},
   "source": [
    "### 2.1.4 MessageGraph源码功能解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dddc45e-e69b-4628-9275-b7557020c958",
   "metadata": {},
   "source": [
    "更复杂一点的，如果我们还想手动更新图状态中的消息（例如人机交互），**使用`operator.add`能做到的功能极限是：发送到图的手动状态更新将被附加到现有的消息列表中，而不是更新现有的消息**。为了避免这种情况，我们则需要一个可以跟踪消息 ID 并覆盖现有消息（如果更新）的`Reducer`函数。为此，就引出了`LangGraph`预构建的`add_messages`函数，这个更高级的`Reducer`所实现的是：**对于全新的消息，它会附加到现有列表，但它也会正确处理现有消息的更新。如何理解这句话呢？我们接下来就从源码角度进行详细解析。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ec1dd-6906-4654-8a4b-b2aaf1d2fd51",
   "metadata": {},
   "source": [
    "`StateGraph`类，这个类允许我们创建图，其节点通过读取和写入共享状态进行通信。 `StateGraph` 类由开发者定义的 `State` 对象进行参数化，该对象表示图中的节点将通过其进行通信的共享数据结构。\n",
    "\n",
    "`MessageGraph` 是 `StateGraph` 的一个子类，使用了 `Annotated[list[AnyMessage], add_messages]` 来初始化其基类 `StateGraph`。这里的 `list[AnyMessage]` 指明了 `MessageGraph` 的状态由消息列表组成，而这个列表类型是一个可以不断添加消息的结构（因为列表是可变的数据类型），`MessageGraph` 中的每个节点都将消息列表作为输入，并返回零个或多个消息作为输出。`add_messages`函数用于将每个节点的输出消息合并进图的状态中已存在的消息列表。其源码定义如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cfcad-7009-4b24-864b-723db3972d72",
   "metadata": {},
   "source": [
    "> MessageGraph 源码：https://github.com/langchain-ai/langgraph/blob/e3ef9adac7395e5c0943c22bbc8a4a856b103aa3/libs/langgraph/langgraph/graph/message.py#L150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0e892-6067-463f-b791-a3e2da90ed20",
   "metadata": {},
   "source": [
    "```python\n",
    "class MessageGraph(StateGraph):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(Annotated[list[AnyMessage], add_messages]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9402c4-557c-4f47-ba04-efc0eed28c39",
   "metadata": {},
   "source": [
    "注意，当前版本MessageGraph已经移除了，使用StateGraph并传入`messages`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4df494-708c-4e5a-8cd0-8983ea4fb27a",
   "metadata": {},
   "source": [
    "我们实际需要的是对消息的一种更新办法，当是旧消息时，进行更新，新消息进行追加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5261c452-d6b8-479a-84ff-3cd784108c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='你好。', additional_kwargs={}, response_metadata={}, id='1'),\n",
       " AIMessage(content='你好，很高兴认识你。', additional_kwargs={}, response_metadata={}, id='2')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "msgs1 = [HumanMessage(content=\"你好。\", id=\"1\")]\n",
    "msgs2 = [AIMessage(content=\"你好，很高兴认识你。\", id=\"2\")]\n",
    "\n",
    "add_messages(msgs1, msgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc4908b1-16a1-452c-9f06-5fdd5fec6057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='你好呀。', additional_kwargs={}, response_metadata={}, id='1')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs1 = [HumanMessage(content=\"你好。\", id=\"1\")]\n",
    "msgs2 = [HumanMessage(content=\"你好呀。\", id=\"1\")]\n",
    "\n",
    "add_messages(msgs1, msgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc6d9af6-b369-4b9f-aa71-cba27cfd02c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='Hello', additional_kwargs={}, response_metadata={}, id='1'), HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='2')]\n"
     ]
    }
   ],
   "source": [
    "msgs1 = [{\"role\": \"assistant\", \"content\": \"Hello\", 'id':\"1\"}]\n",
    "msgs2 = [{\"role\": \"user\", \"content\": \"Hi\", 'id':\"2\"}]\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "merged = add_messages(msgs1, msgs2)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bde4b-21a4-4e98-babb-22fa405a9aad",
   "metadata": {},
   "source": [
    "看起来，对于字典的消息也是可以用的，只不过涉及到结构的转化。因此我们还是基于State来构建历史消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd974647-e95c-45f7-b0b1-6362f598ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Msg2Dict(messages:list):\n",
    "    dict_messages = []\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            role = \"assistant\"\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            role = \"user\"\n",
    "        else:\n",
    "            role = \"system\"  # 如果还有 SystemMessage\n",
    "        dict_messages.append({\n",
    "            \"role\": role,\n",
    "            \"content\": msg.content,\n",
    "            \"id\": msg.id\n",
    "        })\n",
    "    return dict_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "581a62c5-6939-40e7-8922-a2cb3623b318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant', 'content': 'Hello', 'id': '1'},\n",
       " {'role': 'user', 'content': 'Hi', 'id': '2'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Msg2Dict(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "714d8a5d-fb8c-499a-8fb9-8dab4cb1a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1fc1a-1fbf-4ef6-aee7-5a65ec05ceed",
   "metadata": {},
   "source": [
    "`State`是一个带有单个键的`TypedDict` ： `messages` 。 `messages`键使用`add_messages`作为`Reducer`函数告诉 `LangGraph` 将新消息追加到现有列表中，而不是覆盖它。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8006d1-0a4d-4a7e-a1c6-e1281cd1ac84",
   "metadata": {},
   "source": [
    "这样我们就可以实现选中某个历史消息，修改内容重新传入的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805c3e6-787c-40f2-ac6c-253f847607b7",
   "metadata": {},
   "source": [
    "## 2.2 LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea73312-4141-4da7-93d3-1dfd64471f95",
   "metadata": {},
   "source": [
    "大模型具有不确定性，尤其是构建复杂`AI Agent`应用程序中，中间会涉及非常多的子步骤，如果想要了解每一步的运行状态和结果，一方面可以通过`Debug`来进行实时控制，而另一方面可以借助一些工具来观察和调试中间的交互流程。`Langsmith`就是这样一个工具平台， 由 `LangChain` 和 `LangGraph` 背后的团队创建，**主要作用是：为基于大语言模型构建的应用程序提供全面的监控、调试和可观察性。提供强大的跟踪、日志记录和实时分析功能。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1db71c-133f-401d-a9b7-7be7fa1d85ee",
   "metadata": {},
   "source": [
    "> LangSmith：https://smith.langchain.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f6bd0-6010-42ce-a9a2-56a1bc992961",
   "metadata": {},
   "source": [
    "通常，对于一个项目而言，可以是单个应用程序或服务。该项目将包含多个跟踪，每个跟踪都是运行的集合 - 一个运行代表应用程序中的一个基本操作，例如对 OpenAI 的 API 调用，或检索操作。如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b8ed1-2402-4c9b-bd59-2b26da9035a0",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/image-20241022164041124.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec278521-a04a-4c79-b8d8-a1d4a8d750e3",
   "metadata": {},
   "source": [
    "- **Project (项目)：**  \n",
    "  蓝色方块代表整个项目，可能是一个独立的应用程序或服务。\n",
    "\n",
    "- **Traces (轨迹)：**  \n",
    "  绿色方块表示项目在不同条件或配置下的执行路径。每个轨迹可以是特定的用户会话、某个功能的执行，或应用在特定输入下的行为。\n",
    "\n",
    "- **Runs (运行)：**  \n",
    "  每个轨迹下的黄色方块表示该轨迹的单次执行。这些是执行实例，每个实例都是轨迹在特定条件下的实际运行。\n",
    "\n",
    "- **Feedback, Tags, Metadata (反馈、标签、元数据)：**  \n",
    "  显示系统如何利用用户或自动化工具生成的反馈、标签和元数据来增强轨迹的管理和筛选。反馈可以用于改进未来运行，标签和元数据可用于分类和筛选特定轨迹或运行，使其在 LangSmith 用户界面中更易管理和审查。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b5169-eb6c-44a5-9475-55af191fb78c",
   "metadata": {},
   "source": [
    "### 2.2.1 产品注册"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c5afd-9523-48d4-bc1e-5be31cec9cec",
   "metadata": {},
   "source": [
    "要开始使用 `LangSmith`，我们需要创建一个帐户。可以在这里注册一个免费帐户进入`LangSmith`登录页面： https://smith.langchain.com/， 支持使用 Google、GitHub、Discord 和电子邮件登录。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bdc61f-0cc1-47cb-8d5e-2f7eb7ace1aa",
   "metadata": {},
   "source": [
    "在设置中导航至“API 密钥”部分，然后单击“创建 API 密钥” 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09d1c2-1fe0-4371-9706-b531c28fcd78",
   "metadata": {},
   "source": [
    "### 2.2.2 运行一个简单示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a48a25ed-e173-4917-b887-33f702f823a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv('../config/.env')\n",
    "\n",
    "# 获取模型 API 密钥\n",
    "langsmith_api_key = os.getenv(\"LangSmith\")\n",
    "\n",
    "# 设置环境变量\n",
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"First Project\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = langsmith_api_key\n",
    "\n",
    "# 验证环境变量是否设置成功\n",
    "print(os.getenv(\"LANGSMITH_TRACING\"))\n",
    "print(os.getenv(\"LANGSMITH_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09044f53-c2c4-4a35-9185-8ca16402bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 获取模型 API 密钥\n",
    "model_api_key = os.getenv(\"QWEN_API_KEY\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    api_key=model_api_key,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12614d00-277f-4e1e-b7ce-d0869c6a2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    messages = state['messages']\n",
    "    messages = Msg2Dict(messages)\n",
    "    completion = llm.chat.completions.create(\n",
    "        model=\"qwen-turbo-2025-04-28\",\n",
    "        messages=messages,\n",
    "        extra_body={\n",
    "            \"enable_search\": False,\n",
    "            \"enable_thinking\": False\n",
    "        }\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return {\"messages\": [{'role': \"assistant\", 'content': response}]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e1d9cfe-710a-41ea-b824-b2f9211e379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户提问:  你好\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复: 你好！很高兴见到你。有什么我可以帮助你的吗？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户提问:  我在测试langsmith\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复: 你好！很高兴你来测试 LangSmith。LangSmith 是一个用于构建、测试和调试语言模型应用的工具，它可以帮助你更好地理解和优化你的模型在实际应用中的表现。\n",
      "\n",
      "如果你有任何问题或需要帮助的地方，请随时告诉我。比如：\n",
      "\n",
      "- 如何设置 LangSmith？\n",
      "- 如何使用 LangSmith 进行模型测试？\n",
      "- 遇到了什么错误或问题？\n",
      "- 想要了解 LangSmith 的某些功能？\n",
      "\n",
      "我会尽力为你提供帮助！你目前在测试 LangSmith 时遇到了什么具体的问题吗？\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户提问:  你给我讲个短小的笑话\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型回复: 有一天，小明去理发店理发。理发师问他：“要剪什么发型？”  \n",
      "小明说：“剪一个帅气的。”  \n",
      "理发师点点头，开始剪。  \n",
      "结果小明一照镜子，大喊：“这叫帅气？我像狗啃的！”  \n",
      "理发师淡定地说：“不，这是‘汪星人’最新潮流。”\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "用户提问:  退出\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下次再见！\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):  \n",
    "    for event in graph.stream({\"messages\": [{\"role\":\"user\", \"content\":user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"模型回复:\", value[\"messages\"][-1]['content'])\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"用户提问: \")\n",
    "    if user_input.lower() in [\"退出\"]:\n",
    "        print(\"下次再见！\")\n",
    "        break\n",
    "    stream_graph_updates(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1fe67d4-e9e7-48ce-b935-413a1a210581",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************yHoA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 调用模型\u001b[39;00m\n\u001b[32m     12\u001b[39m messages = [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33m请给我写一首关于秋天的诗。\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:190\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    189\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1252\u001b[39m, in \u001b[36mBaseChatModel.__call__\u001b[39m\u001b[34m(self, messages, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m0.1.7\u001b[39m\u001b[33m\"\u001b[39m, alternative=\u001b[33m\"\u001b[39m\u001b[33minvoke\u001b[39m\u001b[33m\"\u001b[39m, removal=\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1231\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1232\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1236\u001b[39m     **kwargs: Any,\n\u001b[32m   1237\u001b[39m ) -> BaseMessage:\n\u001b[32m   1238\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the model.\u001b[39;00m\n\u001b[32m   1239\u001b[39m \n\u001b[32m   1240\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1250\u001b[39m \u001b[33;03m        The model output message.\u001b[39;00m\n\u001b[32m   1251\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     generation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[32m   1256\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation.message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:825\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    823\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    824\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    831\u001b[39m         )\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    833\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1072\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1070\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1076\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1180\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1178\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1180\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1044\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1085\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1086\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\openai\\_base_client.py:1256\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1243\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1244\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1251\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1252\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1253\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1254\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1255\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Anaconda\\envs\\llm\\Lib\\site-packages\\openai\\_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************yHoA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# 创建聊天模型对象\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"qwen-plus\",   # 或者 qwen-7b, qwen-7b-chat 等\n",
    "    temperature=0.7,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "# 调用模型\n",
    "messages = [HumanMessage(content=\"请给我写一首关于秋天的诗。\")]\n",
    "response = llm(messages)\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457b30b-e0ff-45e6-ac47-5acb26730c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
